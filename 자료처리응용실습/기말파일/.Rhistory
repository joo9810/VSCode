first <- crude[[1]]$content %>% str_extract_all('[A-Za-z]+') %>% unlist(first)
first
toupper(first)
str(first)
tolower(first)
lower <- tolower(first)
upper <- toupper(first)
str(first)
lower <- tolower(first)
upper
lower
VCorpus(VectorSource(crude))
crude.corpus <- VCorpus(VectorSource(crude))
str(crude.corpus)
crude.corpus
crude.corpus[[1]]$content
tm_map(crude.corpus,removeNumbers)
crude1 <- tm_map(crude.corpus,removeNumbers)
crude1
crude1[[1]]$content
crude2 <- tm_map(crude1,removePunctuation)
crude2[[1]]$content
crude3 <- tm_map(crude2,stripWhitespace)
crude3[[1]]$content
a <- function(x){
x <- tm_map(x,removeNumbers)
x <- tm_map(x,removePunctuation)
x <- tm_map(x,stripWhitespace)
x <- tm_map(x,removeWords)
return(x)
}
crude3 <- tm_map(crude2,removeWords)
crude3 <- tm_map(crude2,stripWhitespace)
crude3[[1]]$content
x <- tm_map(x,removeWords,stopwords())
return(x)
a <- function(x){
x <- tm_map(x,removeNumbers)
x <- tm_map(x,removePunctuation)
x <- tm_map(x,stripWhitespace)
x <- tm_map(x,removeWords,stopwords())
return(x)
}
a(crude.corpus)
crude.txt <- a(crude.corpus)
crude.txt[[1]]$content
str(crude.txt)
TDM.crude <- TermDocumentMatrix(crude.txt)
TDM.crude
dim(TDM.crude)
inspect(TDM.crude)
rowSums(TDM.crude)
TDM.crude2 <- as.matrix(TDM.crude)
TDM.crude2
TDM.crude3 <- rowSums(TDM.crude2)
TDM.crude3
TDM.crude4 <- TDM.crude3[order(TDM.crude3,decreasing = T)]
TDM.crude4
TDM.crude4[1:10]
#install.packages('tm')
library(tm)
install.packages('tm')
#install.packages('tm')
library(tm)
install.packages('wordcloud')
#install.packages('wordcloud')
library(wordcloud)
install.packages('tidyverse')
#install.packages('tidyverse')
library(tidyverse)
data("crude")
crude
summary(crude)[1:6,]
inspect(crude[1]) # inspect 문서의 정보를 보여주는 함수
crude[[1]]$content # crude의 첫번째 문서의 콘텐츠를 보여줘
first <- crude[[1]]$content %>% str_extract_all(pattern = '[A-Za-z]+') %>% unlist()
first <- toupper(first) # 대문자로 변환
first
first <- tolower(first) # 소문자로 변환환
first
# corpus
crude.corpus <- VCorpus(VectorSource(crude)) # tm함수를 쓰기 위해 corpus 형태로 변환해야함
crude.corpus
crude.corpus[[1]]$content
crude_txt <- tm_map(crude.corpus,removeNumbers) # 숫자 제거
crude_txt[[1]]$content
crude_txt <- tm_map(crude_txt,removePunctuation) # 문장부호 제거
crude_txt[[1]]$content
crude_txt <- tm_map(crude_txt,stripWhitespace) # 공백 제거
crude_txt[[1]]$content
a <- function(x){
x <- tm_map(x, removeNumbers)
x <- tm_map(x, removePunctuation)
x <- tm_map(x, stripWhitespace)
x <- tm_map(x, removeWords, stopwords()) # 불용어 제거 (of a in is 등)
return(x)
}
crude_txt2 <- a(crude.corpus)
crude_txt2[[1]]$content # 숫자와 문장부호와 공백과 불용어가 다 제거된 상태
# TDM
crude.new <- VCorpus(VectorSource(crude_txt2)) # 텍스트를 corpus로 변환하는 함수
crude.new
TDM.crude <- TermDocumentMatrix(crude.new) # TDM(용어문서행렬)으로 변환
dim(TDM.crude)
inspect(TDM.crude) # inspect 문서의 정보를 보여주는 함수
TDM.crude2 <- as.matrix(TDM.crude)
TDM.crude2
TDM.crude3 <- rowSums(TDM.crude2)
TDM.crude4 <- TDM.crude3[order(TDM.crude3,decreasing = T)] # decreasing = T 내림차순
TDM.crude4[1:10] # 빈도표 (1~10위)
# wordcloud
TDM.crude2 <- as.matrix(TDM.crude)
TDM.crude2
sort(rowSums(TDM.crude2),decreasing = T)
crude.freq <- sort(rowSums(TDM.crude2),decreasing = T)
head(crude.freq)
head(crude.freq,10)
wordcloud(words = names(crude.freq),freq = crude.freq,min.freq = 5,
random.order = F)
wordcloud(freq = crude.freq,min.freq = 5,
random.order = F)
wordcloud(words = names(crude.freq),freq = crude.freq,min.freq = 5,
random.order = F)
crude.freq
wordcloud(words = names(crude.freq),freq = crude.freq,min.freq = 5,
random.order = T)
wordcloud(words = names(crude.freq),freq = crude.freq,min.freq = 5,
random.order = F)
library(tm)
library(wordcloud)
library(tidyverse)
data('crude')
crude
summary(crude)[1:6,]
inspect(crude[1])
crude[[1]]$content
crude[[1]]$content %>% str_extract_all(pattern = '[A-Za-z]+')
crude[[1]]$content %>% str_extract_all(pattern = '[A-Za-z]+') %>% unlist()
first <- crude[[1]]$content %>% str_extract_all(pattern = '[A-Za-z]+') %>% unlist()
first2 <- toupper(first)
first2
first3 <- tolower(first2)
first3
first
str(crude)
VCorpus(VectorSource(crude))
crude.corpus <- VCorpus(VectorSource(crude))
crude.corpus
crude
crude.corpus[[1]]$content
crude.txt <- tm_map(crude.corpus,removeNumbers)
crude.txt2 <- tm_map(crude.corpus,removePunctuation)
crude.txt2 <- tm_map(crude.txt,removePunctuation)
crude.txt3 <- tm_map(crude.txt2,stripWhitespace)
crude.txt3[[1]]$content
a <- function(x){
x <- tm_map(x,removeNumbers)
x <- tm_map(x,removePunctuation)
x <- tm_map(x,stripWhitespace)
x <- tm_map(x,removeWords, stopwords())
}
a(crude.corpus)
crude.txt4 <- a(crude.corpus)
crude.txt4
crude.txt4[[1]]$content
return(x)
a <- function(x){
x <- tm_map(x,removeNumbers)
x <- tm_map(x,removePunctuation)
x <- tm_map(x,stripWhitespace)
x <- tm_map(x,removeWords, stopwords())
return(x)
}
crude.txt4 <- a(crude.corpus)
crude.txt4[[1]]$content
crude.new <- VCorpus(VectorSource(crude.txt4))
crude.new
TDM.crude <- TermDocumentMatrix(crude.new)
dim(TDM.crude)
inspect(TDM.crude)
TDM.crude2 <- as.matrix(TDM.crude)
TDM.crude2
rowSums(TDM.crude2)
TDM.crude3 <- rowSums(TDM.crude2)
TDM.crude3 <- rowSums(TDM.crude2) %>% head(10)
TDM.crude3
TDM.crude4 <- TDM.crude3[order(TDM.crude3,decreasing = T)]
TDM.crude4
TDM.crude2
TDM.crude3 <- rowSums(TDM.crude2)
TDM.crude4 <- TDM.crude3[order(TDM.crude3,decreasing = T)]
TDM.crude4
TDM.crude4
TDM.crude4[1:10]
TDM.crude4 %>% head(10)
TDM.crude4 %>% head(10) # 빈도표 (1~10위)
TDM.crude4[1:10] # 빈도표 (1~10위)
# wordcloud
TDM.crude2 <- as.matrix(TDM.crude)
crude.freq <- sort(rowSums(TDM.crude2),decreasing = T) # TDM.crude2의 행의 합을 구해 내림차순
head(crude.freq,10)
wordcloud(words = names(crude.freq),freq = crude.freq,min.freq = 5,random.order = F,
colors = brewer.pal(8,'Dark2'))
wordcloud(words = names(TDM.crude4),freq = TDM.crude4,
min.freq = 5,random.order = F)
wordcloud(words = names(crude.freq),freq = crude.freq,min.freq = 5,random.order = F,
colors = brewer.pal(8,'Dark2'))
wordcloud(words = names(TDM.crude4),freq = TDM.crude4,
min.freq = 5,random.order = F)
wordcloud(words = names(TDM.crude4),freq = TDM.crude4,
min.freq = 5,random.order = F,colors = brewer.pal(8,'Dark2'))
wordcloud(words = names(TDM.crude4),freq = TDM.crude4,
min.freq = 5,random.order = F,colors = brewer.pal(8,'Dark2'))
wordcloud(words = names(TDM.crude4),freq = TDM.crude4,
min.freq = 5,random.order = F,colors = brewer.pal(8,'Dark2'))
Sys.Date()
today <- Sys.Date()
today
searchWord <- 'covid19'
ref <- 'https://section.blog.naver.com/BlogHome.nhn'
ref
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn',
query = list(countPerPage=7,
currentPage=1,
endDate=today,
startDate=today,
keyword=searchWord))
library(httr)
library(rvest)
library(jsonlite)
library(stringr)
library(dplyr)
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn',
query = list(countPerPage=7,
currentPage=1,
endDate=today,
startDate=today,
keyword=searchWord))
res
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn',
query = list(countPerPage=7,
currentPage=1,
endDate=today,
startDate=today,
keyword=searchWord,
add_headers(referer = ref)))
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn',
query = list(countPerPage=7,
currentPage=1,
endDate=today,
startDate=today,
keyword=searchWord),
add_headers(referer = ref))
res
# 헤더 부분의 리퀘스트 url의 ? 앞까지 붙혀넣기
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn',
query = list(countPerPage=7,
currentPage=1,
startDate=today,
endDate=today,
keyword=searchWord),
add_headers(referer = ref)) #참조 사이트를 ref로 해달라
res
json <- res %>% content(as='text') %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\',") %>% fromJSON()
json
str(json)
json$result$totalCount # 총 블로그 수 400개
json <- res %>% content(as='text') %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\',") %>% fromJSON()
json
json
str(json)
json$result$totalCount # 총 블로그 수 400개
df <- json$result$searchList
df <- df %>% select(blogId,postUrl,noTagTitle,nickName,blogName,addDate,contents)
View(df)
df$addDate <- as.POSIXct(df$addDate/1000,origin = '1970-01-01')
df$addDate
colnames(df) <- c('bid','url','head','nickNm','blogNm','Date','contents')
View(df) # 이름이 다 바뀐 상태임
saveRDS(df, file = 'df.RDS') # df를 df.RDS로 저장
df_RDS <- readRDS('df.RDS')
df_RDS
str(df_RDS) # 최종적으로 비정형데이터를 R파일로 변환시켰기 때문에 이제 이걸로
library(rvest)
page1 <- read_html('https://finance.yahoo.com/quote/MSFT?p=MSFT')
page1
# 특정 요소 추출, quote-header-info는 id, id는 앞에 #
page1 %>% html_node('#quote-header-info div:nth-child(1) h1') %>%
html()
# 특정 요소 추출, quote-header-info는 id, id는 앞에 #
page1 %>% html_node('#quote-header-info div:nth-child(1) h1') %>%
html_text()
page2 <- read_html('https://finance.yahoo.com/quote/MSFT?p=MSFT')
page2 %>% html_node('#quote-header-info div:nth-child(2) span') %>%
html_text()
page3 <- read_html('https://finance.yahoo.com/quote/MSFT?p=MSFT')
page3 %>% html_node('#quote-header-info div:nth-child(3) span') %>%
html_text()
page3 %>% html_node('#quote-header-info div:nth-child(3) span') %>%
html_text() %>% as.numeric
page4 <- read_html('https://cran.rstudio.com/web/packages/available_packages_by_name.html')
pkg_table <- page4 %>% html_node('table') %>% html_table(fill = T)
pkg_table <- page4 %>% html_node('table') %>% html_table(fill = T) %>% head(pkg_table)
pkg_table
pkg_table <- page4 %>% html_node('table') %>% html_table(fill = T)
head(pkg_table)
pkg_table <- pkg_table[complete.cases(pkg_table),]
pkg_table
pkg_table <- pkg_table[complete.cases(pkg_table),]
pkg_table
colnames(pkg_table) <- c('pkg_name','title')
pkg_table <- pkg_table[complete.cases(pkg_table),] # 결측치 제거
pkg_table
colnames(pkg_table) <- c('pkg_name','title')
head(pkg_table)
as.data.frame(pkg_table)
pkg_df <- as.data.frame(pkg_table)
pkg_df
head(pkg_table)
str(pkg_df)
write.csv(pkg_df,file = 'pkg_R.csv')
write.csv(pkg_df,file = 'pkg_R.csv')
page5 <- read_html('http://it.chosun.com/site/data/html_dir/2017/09/27/2017092785016.html')
page5 %>% html.node('#news_title_text_id div:nth-child(1) h1') %>%
html_text()
page5 %>% html_node('#news_title_text_id div:nth-child(1) h1') %>%
html_text()
page5 %>% html_node('h1#news_title_text_id') %>% html_text()
page3 %>% html_node('h1.D(ib) Fz(18px)') %>% html_text()
# 특정 요소 추출, quote-header-info는 id, id는 앞에 #
page1 %>% html_node('#quote-header-info div:nth-child(1) h1') %>%
html_text()
page2 %>% html_node('#quote-header-info div:nth-child(2) span') %>%
html_text()
page3 %>% html_node('h1.D(ib).Fz(18px)') %>% html_text()
page3 %>% html_node('div.D(ib)') %>% html_text()
page3 %>% html_node('h1.D(ib).Fz(18px)') %>% html_text()
page4 %>% html_node('h1') %>% html_text()
page6 <- read_html('https://finance.yahoo.com/quote/MSFT?p=MSFT')
page6 %>% html_node('h1.D(ib).Fz(18px)') %>% html_text()
page4 %>% html_node('h1') %>% html_text()
page5 %>% html_node('div.par') %>% html_text()
page6 %>% html_node('h1') %>% html_text()
library(httr)
library(rvest)
library(jsonlite)
library(stringr)
library(dplyr)
library(tidyverse)
today <- Sys.Date()
today
ref <- 'https://section.blog.naver.com/BlogHome.nhn'
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn'
query = list(countPerPage=7,
currentPage=1,
endDate=2021-05-26,
startDate=2021-05-26,
keyword=covid),
add_headers(referer = ref))
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn'
query = list(countPerPage=7,
currentPage=1,
endDate=2021-05-26,
startDate=2021-05-26,
keyword='covid'),
add_headers(referer = ref))
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn',
query = list(countPerPage=7,
currentPage=1,
endDate=2021-05-26,
startDate=2021-05-26,
keyword=covid),
add_headers(referer = ref))
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn',
query = list(countPerPage=7,
currentPage=1,
endDate=2021-05-26,
startDate=2021-05-26,
keyword='covid'),
add_headers(referer = ref))
res
json <- res %>% content(as='text') %>% fromJSON()
json <- res %>% content(as='text')
json
res
json <- res %>% content(as='text') %>% fromJSON()
json <- res %>% content(as='text')
json
json <- res %>% content(as='text') %>% fromJSON()
json <- res %>% content(as='text') %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = ")]}',")
json <- res %>% content(as='text') %>% str_remove(pattern = ")]}',")
json <- res %>% content(as='text') %>% fromJSON()
json <- res %>% content(as='text')
json
json <- res %>% content(as='text') %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\',") %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\'") %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\',1") %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\',1") %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\',") %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\'\\,") %>% fromJSON()
json
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\',") %>% fromJSON()
json
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\'\\,") %>% fromJSON()
json
str(json)
json$result$totalCount
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn',
query = list(countPerPage=7,
currentPage=1,
endDate=2021-05-25,
startDate=2021-05-25,
keyword='covid'),
add_headers(referer = ref))
res
json <- res %>% content(as='text') %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\'\\,") %>% fromJSON()
json
str(json)
json$result$totalCount
# 헤더 부분의 리퀘스트 url의 ? 앞까지 붙혀넣기
res <- GET(url = 'https://section.blog.naver.com/ajax/SearchList.nhn',
query = list(countPerPage=7,
currentPage=1,
startDate=today,
endDate=today,
keyword=searchWord),
add_headers(referer = ref)) #참조 사이트를 ref로 해달라
res
json <- res %>% content(as='text') %>% fromJSON()
json <- res %>% content(as='text') %>% str_remove(pattern = "\\)\\]\\}\\',") %>% fromJSON()
json
str(json)
json$result$totalCount # 총 블로그 수
json$result$searchList
df <- json$result$searchList
df %>% select(blogId,postUrl,noTagTitle,nickName,blogName,addDate,contents)
df2 <- df %>% select(blogId,postUrl,noTagTitle,nickName,blogName,addDate,contents)
View(df2)
str(df)
df$addDate <- as.POSIXct(df$addDate/1000,origin = '1970-01-01')
df$addDate
df$addDate
df <- json$result$searchList
df <- df %>% select(blogId,postUrl,noTagTitle,nickName,blogName,addDate,contents)
df$addDate
df$addDate <- as.POSIXct(df$addDate,origin = '1970-01-01')
df$addDate
df$addDate <- as.POSIXct(df$addDate/1000,origin = '1970-01-01')
df$addDate <- as.POSIXct(df$addDate/1000,origin = '1970-01-01')
df$addDate <- as.POSIXct(df$addDate/1000,origin = '1970-01-01')
df <- json$result$searchList
df <- df %>% select(blogId,postUrl,noTagTitle,nickName,blogName,addDate,contents)
View(df) # data.frame으로 된 형식을 정리해서 보여줌
df$addDate <- as.POSIXct(df$addDate/1000,origin = '1970-01-01')
df$addDate
df <- json$result$searchList
df <- df %>% select(blogId,postUrl,noTagTitle,nickName,blogName,addDate,contents)
View(df) # data.frame으로 된 형식을 정리해서 보여줌
df$addDate <- as.POSIXct(df$addDate,origin = '1970-01-01')
df$addDate
df$addDate <- as.POSIXct(df$addDate/1000,origin = '1970-01-01')
df <- json$result$searchList
df <- df %>% select(blogId,postUrl,noTagTitle,nickName,blogName,addDate,contents)
df$addDate
df$addDate <- as.POSIXct(df$addDate/1000)
df$addDate <- as.POSIXct(df$addDate/1000,origin = '1970-01-01')
df$addDate
df <- json$result$searchList
df2 <- df %>% select(blogId,postUrl,noTagTitle,nickName,blogName,addDate,contents)
View(df2)
df$addDate
df$addDate <- as.POSIXct(df$addDate,origin = '1970-01-01')
df$addDate
df <- json$result$searchList
df
df$addDate <- as.POSIXlt(df$addDate,origin = '1970-01-01')
df$addDate
df2 <- df %>% select(blogId,postUrl,noTagTitle,nickName,blogName,addDate,contents)
df <- json$result$searchList
df2 <- df %>% select(blogId,postUrl,noTagTitle,nickName,blogName,addDate,contents)
df$addDate <- as.POSIXlt(df$addDate/1000,origin = '1970-01-01')
df$addDate
df
colnames(df2) <- c('bid','url','head','nickNm','blogNm','Date','contents')
df2
View(df2)
readRDS('df.RDS')
df2
readRDS('df.RDS')
df2$contents
df.RDS <- readRDS('df.RDS')
df.RDS$contents
df2 %>% filter('3')
str(df2)
str(df2)
str(df.RDS)
df.RDS <- readRDS('df.RDS')
df2$contents
df.RDS$contents
save.RDS(df2, file = 'df.RDS')
saveRDS(df2, file = 'df.RDS')
df.RDS <- readRDS('df.RDS')
df2$contents
df.RDS$contents
df.RDS$contents
str(df2)
str(df.RDS)
