{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(DataFile):\n",
    "    en1_dict = {}\n",
    "\n",
    "    en1 = []\n",
    "\n",
    "    with open(DataFile, 'r', encoding='utf-8') as f:\n",
    "        for i in f:\n",
    "            if (i != '\\n') and len(i.strip()) >= 2:\n",
    "                en1.append(i.strip())\n",
    "\n",
    "    en1_dict = {chr(i) : 0 for i in range(97, 123)}\n",
    "\n",
    "    for i in en1:\n",
    "        for j in i:\n",
    "            if (65 <= ord(j) <= 90) or (97 <= ord(j) <= 122):\n",
    "                en1_dict[j.lower()] += 1\n",
    "\n",
    "    return {key : value for key, value in zip(en1_dict.keys(), [i/sum(en1_dict.values()) for i in en1_dict.values()])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_train(language, dataset, start_num):\n",
    "    en1 = f'[머신러닝] 과제 데이터셋/{dataset}/{language}-{start_num}.txt'\n",
    "    en2 = f'[머신러닝] 과제 데이터셋/{dataset}/{language}-{start_num+1}.txt'\n",
    "    en3 = f'[머신러닝] 과제 데이터셋/{dataset}/{language}-{start_num+2}.txt'\n",
    "    en4 = f'[머신러닝] 과제 데이터셋/{dataset}/{language}-{start_num+3}.txt'\n",
    "    en5 = f'[머신러닝] 과제 데이터셋/{dataset}/{language}-{start_num+4}.txt'\n",
    "\n",
    "    en_df = pd.DataFrame([make_dict(en1), make_dict(en2), make_dict(en3),\n",
    "                        make_dict(en4), make_dict(en5)])\n",
    "    en_df['language'] = [language] * 5\n",
    "    return en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = make_df_train('en', 'train', 1)\n",
    "train_fr = make_df_train('fr', 'train', 6)\n",
    "train_id = make_df_train('id', 'train', 11)\n",
    "train_tl = make_df_train('tl', 'train', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>...</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.076101</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>0.045792</td>\n",
       "      <td>0.046228</td>\n",
       "      <td>0.104884</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.019189</td>\n",
       "      <td>0.043829</td>\n",
       "      <td>0.074139</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077846</td>\n",
       "      <td>0.061491</td>\n",
       "      <td>0.080026</td>\n",
       "      <td>0.025949</td>\n",
       "      <td>0.009158</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.020061</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.084238</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>0.030426</td>\n",
       "      <td>0.038898</td>\n",
       "      <td>0.136857</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.031261</td>\n",
       "      <td>0.027443</td>\n",
       "      <td>0.075409</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090204</td>\n",
       "      <td>0.071710</td>\n",
       "      <td>0.077556</td>\n",
       "      <td>0.030665</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.013960</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071825</td>\n",
       "      <td>0.012202</td>\n",
       "      <td>0.045757</td>\n",
       "      <td>0.032723</td>\n",
       "      <td>0.119523</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.023572</td>\n",
       "      <td>0.094842</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054077</td>\n",
       "      <td>0.088186</td>\n",
       "      <td>0.080422</td>\n",
       "      <td>0.029118</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072251</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>0.039615</td>\n",
       "      <td>0.120921</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.023580</td>\n",
       "      <td>0.059045</td>\n",
       "      <td>0.065271</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059234</td>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.093567</td>\n",
       "      <td>0.024335</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.019619</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073806</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>0.031099</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>0.141261</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>0.056943</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072492</td>\n",
       "      <td>0.059571</td>\n",
       "      <td>0.095488</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>0.010731</td>\n",
       "      <td>0.023872</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.014893</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.077913</td>\n",
       "      <td>0.014919</td>\n",
       "      <td>0.035749</td>\n",
       "      <td>0.044830</td>\n",
       "      <td>0.149735</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.072003</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074741</td>\n",
       "      <td>0.082093</td>\n",
       "      <td>0.070561</td>\n",
       "      <td>0.054452</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.072717</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.035412</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.011528</td>\n",
       "      <td>0.071416</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076914</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>0.065681</td>\n",
       "      <td>0.050902</td>\n",
       "      <td>0.012711</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.072608</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.157130</td>\n",
       "      <td>0.013032</td>\n",
       "      <td>0.013529</td>\n",
       "      <td>0.014397</td>\n",
       "      <td>0.085516</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082040</td>\n",
       "      <td>0.066526</td>\n",
       "      <td>0.061065</td>\n",
       "      <td>0.042696</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.143275</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>0.019493</td>\n",
       "      <td>0.089864</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.063353</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.078738</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.037253</td>\n",
       "      <td>0.053283</td>\n",
       "      <td>0.150487</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>0.069377</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075083</td>\n",
       "      <td>0.071621</td>\n",
       "      <td>0.077584</td>\n",
       "      <td>0.053475</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.126248</td>\n",
       "      <td>0.031936</td>\n",
       "      <td>0.014471</td>\n",
       "      <td>0.034431</td>\n",
       "      <td>0.096806</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.059880</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.104790</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076846</td>\n",
       "      <td>0.068862</td>\n",
       "      <td>0.046906</td>\n",
       "      <td>0.042415</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.006487</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.147611</td>\n",
       "      <td>0.024581</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.039455</td>\n",
       "      <td>0.093407</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>0.033909</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>0.100340</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046641</td>\n",
       "      <td>0.081306</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.177381</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.083661</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.049591</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>0.087158</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052067</td>\n",
       "      <td>0.047587</td>\n",
       "      <td>0.049866</td>\n",
       "      <td>0.048530</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.014579</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.169341</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.032431</td>\n",
       "      <td>0.069764</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.045122</td>\n",
       "      <td>0.015041</td>\n",
       "      <td>0.097428</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050091</td>\n",
       "      <td>0.054187</td>\n",
       "      <td>0.049822</td>\n",
       "      <td>0.046666</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.180167</td>\n",
       "      <td>0.025469</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.046130</td>\n",
       "      <td>0.083635</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.034143</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.088752</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.054203</td>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.043288</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.012929</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.223182</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.096366</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>0.087216</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>0.049043</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>0.027486</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.219981</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.013994</td>\n",
       "      <td>0.023060</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.089897</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.085151</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023182</td>\n",
       "      <td>0.054121</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.032673</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.028171</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.229756</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.012777</td>\n",
       "      <td>0.029812</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.091454</td>\n",
       "      <td>0.011264</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026898</td>\n",
       "      <td>0.047352</td>\n",
       "      <td>0.059569</td>\n",
       "      <td>0.034744</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.177605</td>\n",
       "      <td>0.022741</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.064937</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.066926</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>0.074535</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045914</td>\n",
       "      <td>0.058971</td>\n",
       "      <td>0.054734</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.023346</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.202369</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>0.037057</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.033062</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.075492</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039399</td>\n",
       "      <td>0.065023</td>\n",
       "      <td>0.046150</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.033889</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           a         b         c         d         e         f         g  \\\n",
       "0   0.076101  0.012865  0.045792  0.046228  0.104884  0.015700  0.019189   \n",
       "1   0.084238  0.019926  0.030426  0.038898  0.136857  0.017420  0.031261   \n",
       "2   0.071825  0.012202  0.045757  0.032723  0.119523  0.014698  0.025236   \n",
       "3   0.072251  0.027731  0.029994  0.039615  0.120921  0.016789  0.023580   \n",
       "4   0.073806  0.020368  0.031099  0.039641  0.141261  0.020368  0.020368   \n",
       "5   0.077913  0.014919  0.035749  0.044830  0.149735  0.011784  0.011496   \n",
       "6   0.072717  0.013065  0.035412  0.044990  0.150754  0.010523  0.010582   \n",
       "7   0.072608  0.015763  0.039841  0.051136  0.157130  0.013032  0.013529   \n",
       "8   0.078947  0.011501  0.035283  0.051852  0.143275  0.012086  0.020078   \n",
       "9   0.078738  0.010451  0.037253  0.053283  0.150487  0.016222  0.010708   \n",
       "10  0.126248  0.031936  0.014471  0.034431  0.096806  0.004491  0.059880   \n",
       "11  0.147611  0.024581  0.009202  0.039455  0.093407  0.011093  0.033909   \n",
       "12  0.177381  0.023302  0.005501  0.038746  0.083661  0.012693  0.049591   \n",
       "13  0.169341  0.025045  0.004566  0.032431  0.069764  0.007923  0.045122   \n",
       "14  0.180167  0.025469  0.008251  0.046130  0.083635  0.005117  0.034143   \n",
       "15  0.223182  0.024521  0.008125  0.013139  0.024229  0.003514  0.096366   \n",
       "16  0.219981  0.017919  0.004989  0.013994  0.023060  0.001795  0.089897   \n",
       "17  0.229756  0.021014  0.002522  0.012777  0.029812  0.000280  0.091454   \n",
       "18  0.177605  0.022741  0.019023  0.021790  0.064937  0.004929  0.066926   \n",
       "19  0.202369  0.022730  0.019562  0.037057  0.064196  0.005786  0.033062   \n",
       "\n",
       "           h         i         j  ...         r         s         t         u  \\\n",
       "0   0.043829  0.074139  0.001744  ...  0.077846  0.061491  0.080026  0.025949   \n",
       "1   0.027443  0.075409  0.002625  ...  0.090204  0.071710  0.077556  0.030665   \n",
       "2   0.023572  0.094842  0.002496  ...  0.054077  0.088186  0.080422  0.029118   \n",
       "3   0.059045  0.065271  0.001509  ...  0.059234  0.073382  0.093567  0.024335   \n",
       "4   0.056943  0.065046  0.003285  ...  0.072492  0.059571  0.095488  0.024967   \n",
       "5   0.012613  0.072003  0.002126  ...  0.074741  0.082093  0.070561  0.054452   \n",
       "6   0.011528  0.071416  0.003015  ...  0.076914  0.078333  0.065681  0.050902   \n",
       "7   0.014397  0.085516  0.004344  ...  0.082040  0.066526  0.061065  0.042696   \n",
       "8   0.019493  0.089864  0.003899  ...  0.077778  0.072320  0.063353  0.043860   \n",
       "9   0.015517  0.069377  0.002308  ...  0.075083  0.071621  0.077584  0.053475   \n",
       "10  0.013972  0.104790  0.003992  ...  0.076846  0.068862  0.046906  0.042415   \n",
       "11  0.018530  0.100340  0.005294  ...  0.046641  0.081306  0.050800  0.040590   \n",
       "12  0.018666  0.087158  0.007388  ...  0.052067  0.047587  0.049866  0.048530   \n",
       "13  0.015041  0.097428  0.006647  ...  0.050091  0.054187  0.049822  0.046666   \n",
       "14  0.020840  0.088752  0.009064  ...  0.056915  0.054203  0.050240  0.043288   \n",
       "15  0.018775  0.087216  0.001244  ...  0.017677  0.049043  0.054496  0.027486   \n",
       "16  0.016884  0.085151  0.000700  ...  0.023182  0.054121  0.044872  0.032673   \n",
       "17  0.011264  0.070384  0.001793  ...  0.026898  0.047352  0.059569  0.034744   \n",
       "18  0.019023  0.074535  0.001902  ...  0.045914  0.058971  0.054734  0.027756   \n",
       "19  0.006750  0.075492  0.002342  ...  0.039399  0.065023  0.046150  0.027828   \n",
       "\n",
       "           v         w         x         y         z  language  \n",
       "0   0.009158  0.014174  0.000654  0.020061  0.000436        en  \n",
       "1   0.013483  0.013960  0.002028  0.010739  0.000597        en  \n",
       "2   0.018026  0.011925  0.000555  0.018026  0.000555        en  \n",
       "3   0.004905  0.019619  0.006037  0.017544  0.001698        en  \n",
       "4   0.010731  0.023872  0.003066  0.014893  0.000657        en  \n",
       "5   0.010631  0.004541  0.003892  0.005334  0.000468        fr  \n",
       "6   0.012711  0.002601  0.004966  0.004848  0.000118        fr  \n",
       "7   0.015142  0.000745  0.005089  0.004965  0.001986        fr  \n",
       "8   0.014035  0.000390  0.003314  0.005263  0.001170        fr  \n",
       "9   0.014299  0.000705  0.003911  0.003655  0.000834        fr  \n",
       "10  0.003992  0.006487  0.001497  0.009481  0.001497        id  \n",
       "11  0.008068  0.005042  0.001387  0.013614  0.000630        id  \n",
       "12  0.001572  0.004087  0.000236  0.014579  0.000236        id  \n",
       "13  0.002216  0.001813  0.000201  0.011750  0.000537        id  \n",
       "14  0.003005  0.006237  0.000309  0.012929  0.001137        id  \n",
       "15  0.002452  0.012371  0.000512  0.020130  0.001061        tl  \n",
       "16  0.000639  0.009096  0.000304  0.028171  0.000152        tl  \n",
       "17  0.001065  0.014290  0.000056  0.019725  0.000056        tl  \n",
       "18  0.005102  0.008214  0.000865  0.023346  0.002681        tl  \n",
       "19  0.004822  0.005786  0.000413  0.033889  0.003031        tl  \n",
       "\n",
       "[20 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_en, train_fr, train_id, train_tl]).reset_index(drop = True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_test(language, dataset, start_num):\n",
    "    en1 = f'[머신러닝] 과제 데이터셋/{dataset}/{language}-{start_num}.txt'\n",
    "    en2 = f'[머신러닝] 과제 데이터셋/{dataset}/{language}-{start_num+1}.txt'\n",
    "\n",
    "    en_df = pd.DataFrame([make_dict(en1), make_dict(en2)])\n",
    "    en_df['language'] = [language] * 2\n",
    "    return en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_en = make_df_test('en', 'test', 1)\n",
    "test_fr = make_df_test('fr', 'test', 3)\n",
    "test_id = make_df_test('id', 'test', 5)\n",
    "test_tl = make_df_test('tl', 'test', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>...</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067845</td>\n",
       "      <td>0.013464</td>\n",
       "      <td>0.034339</td>\n",
       "      <td>0.048833</td>\n",
       "      <td>0.116042</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.016007</td>\n",
       "      <td>0.022805</td>\n",
       "      <td>0.076945</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070147</td>\n",
       "      <td>0.079576</td>\n",
       "      <td>0.075037</td>\n",
       "      <td>0.025919</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>0.036115</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080292</td>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.038346</td>\n",
       "      <td>0.129841</td>\n",
       "      <td>0.016706</td>\n",
       "      <td>0.018952</td>\n",
       "      <td>0.042702</td>\n",
       "      <td>0.073995</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066235</td>\n",
       "      <td>0.063606</td>\n",
       "      <td>0.078850</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056764</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.035835</td>\n",
       "      <td>0.049876</td>\n",
       "      <td>0.127155</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.086050</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067304</td>\n",
       "      <td>0.090078</td>\n",
       "      <td>0.068433</td>\n",
       "      <td>0.042912</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.071875</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.038476</td>\n",
       "      <td>0.040330</td>\n",
       "      <td>0.139357</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.015386</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>0.079491</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064060</td>\n",
       "      <td>0.073023</td>\n",
       "      <td>0.066334</td>\n",
       "      <td>0.048652</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104424</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.089460</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>0.026675</td>\n",
       "      <td>0.015615</td>\n",
       "      <td>0.090599</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069616</td>\n",
       "      <td>0.079050</td>\n",
       "      <td>0.052863</td>\n",
       "      <td>0.036923</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.164742</td>\n",
       "      <td>0.026059</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.041585</td>\n",
       "      <td>0.088281</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>0.036007</td>\n",
       "      <td>0.025123</td>\n",
       "      <td>0.082078</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>0.053250</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.185617</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>0.026729</td>\n",
       "      <td>0.033097</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.082552</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.081751</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035842</td>\n",
       "      <td>0.058720</td>\n",
       "      <td>0.052162</td>\n",
       "      <td>0.023793</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.017082</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.167981</td>\n",
       "      <td>0.016374</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>0.055791</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>0.066707</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>0.070346</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044269</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.016374</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e         f         g  \\\n",
       "0  0.067845  0.013464  0.034339  0.048833  0.116042  0.020020  0.016007   \n",
       "1  0.080292  0.016176  0.035354  0.038346  0.129841  0.016706  0.018952   \n",
       "2  0.056764  0.012008  0.035835  0.049876  0.127155  0.013476  0.008620   \n",
       "3  0.071875  0.011413  0.038476  0.040330  0.139357  0.012185  0.015386   \n",
       "4  0.104424  0.022121  0.015290  0.044242  0.089460  0.011386  0.026675   \n",
       "5  0.164742  0.026059  0.014590  0.041585  0.088281  0.005969  0.036007   \n",
       "6  0.185617  0.019561  0.014375  0.026729  0.033097  0.007969  0.082552   \n",
       "7  0.167981  0.016374  0.018799  0.024864  0.055791  0.009096  0.066707   \n",
       "\n",
       "          h         i         j  ...         r         s         t         u  \\\n",
       "0  0.022805  0.076945  0.002412  ...  0.070147  0.079576  0.075037  0.025919   \n",
       "1  0.042702  0.073995  0.004463  ...  0.066235  0.063606  0.078850  0.027634   \n",
       "2  0.007303  0.086050  0.002786  ...  0.067304  0.090078  0.068433  0.042912   \n",
       "3  0.018410  0.079491  0.004150  ...  0.064060  0.073023  0.066334  0.048652   \n",
       "4  0.015615  0.090599  0.005368  ...  0.069616  0.079050  0.052863  0.036923   \n",
       "5  0.025123  0.082078  0.007256  ...  0.053640  0.048802  0.053250  0.047437   \n",
       "6  0.014070  0.081751  0.000229  ...  0.035842  0.058720  0.052162  0.023793   \n",
       "7  0.011522  0.070346  0.000606  ...  0.044269  0.052759  0.061249  0.036992   \n",
       "\n",
       "          v         w         x         y         z  language  \n",
       "0  0.014670  0.036115  0.005635  0.013091  0.000417        en  \n",
       "1  0.012988  0.014881  0.002119  0.013302  0.001491        en  \n",
       "2  0.013852  0.028909  0.009298  0.005157  0.000414        fr  \n",
       "3  0.013598  0.002892  0.004282  0.003355  0.001192        fr  \n",
       "4  0.016591  0.033669  0.004880  0.009597  0.000488        id  \n",
       "5  0.004681  0.004603  0.000468  0.014824  0.000585        id  \n",
       "6  0.004804  0.028369  0.003394  0.017082  0.000419        tl  \n",
       "7  0.001819  0.016374  0.000606  0.018193  0.000606        tl  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat([test_en, test_fr, test_id, test_tl]).reset_index(drop = True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>...</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.076101</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>0.045792</td>\n",
       "      <td>0.046228</td>\n",
       "      <td>0.104884</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.019189</td>\n",
       "      <td>0.043829</td>\n",
       "      <td>0.074139</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077846</td>\n",
       "      <td>0.061491</td>\n",
       "      <td>0.080026</td>\n",
       "      <td>0.025949</td>\n",
       "      <td>0.009158</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.020061</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.084238</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>0.030426</td>\n",
       "      <td>0.038898</td>\n",
       "      <td>0.136857</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.031261</td>\n",
       "      <td>0.027443</td>\n",
       "      <td>0.075409</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090204</td>\n",
       "      <td>0.071710</td>\n",
       "      <td>0.077556</td>\n",
       "      <td>0.030665</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.013960</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071825</td>\n",
       "      <td>0.012202</td>\n",
       "      <td>0.045757</td>\n",
       "      <td>0.032723</td>\n",
       "      <td>0.119523</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.023572</td>\n",
       "      <td>0.094842</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054077</td>\n",
       "      <td>0.088186</td>\n",
       "      <td>0.080422</td>\n",
       "      <td>0.029118</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072251</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>0.039615</td>\n",
       "      <td>0.120921</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.023580</td>\n",
       "      <td>0.059045</td>\n",
       "      <td>0.065271</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059234</td>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.093567</td>\n",
       "      <td>0.024335</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.019619</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073806</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>0.031099</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>0.141261</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>0.056943</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072492</td>\n",
       "      <td>0.059571</td>\n",
       "      <td>0.095488</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>0.010731</td>\n",
       "      <td>0.023872</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.014893</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.077913</td>\n",
       "      <td>0.014919</td>\n",
       "      <td>0.035749</td>\n",
       "      <td>0.044830</td>\n",
       "      <td>0.149735</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.072003</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074741</td>\n",
       "      <td>0.082093</td>\n",
       "      <td>0.070561</td>\n",
       "      <td>0.054452</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.072717</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.035412</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.011528</td>\n",
       "      <td>0.071416</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076914</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>0.065681</td>\n",
       "      <td>0.050902</td>\n",
       "      <td>0.012711</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.072608</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.157130</td>\n",
       "      <td>0.013032</td>\n",
       "      <td>0.013529</td>\n",
       "      <td>0.014397</td>\n",
       "      <td>0.085516</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082040</td>\n",
       "      <td>0.066526</td>\n",
       "      <td>0.061065</td>\n",
       "      <td>0.042696</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.143275</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>0.019493</td>\n",
       "      <td>0.089864</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.063353</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.078738</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.037253</td>\n",
       "      <td>0.053283</td>\n",
       "      <td>0.150487</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>0.069377</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075083</td>\n",
       "      <td>0.071621</td>\n",
       "      <td>0.077584</td>\n",
       "      <td>0.053475</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.126248</td>\n",
       "      <td>0.031936</td>\n",
       "      <td>0.014471</td>\n",
       "      <td>0.034431</td>\n",
       "      <td>0.096806</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.059880</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.104790</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076846</td>\n",
       "      <td>0.068862</td>\n",
       "      <td>0.046906</td>\n",
       "      <td>0.042415</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.006487</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.147611</td>\n",
       "      <td>0.024581</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.039455</td>\n",
       "      <td>0.093407</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>0.033909</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>0.100340</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046641</td>\n",
       "      <td>0.081306</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.177381</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.083661</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.049591</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>0.087158</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052067</td>\n",
       "      <td>0.047587</td>\n",
       "      <td>0.049866</td>\n",
       "      <td>0.048530</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.014579</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.169341</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.032431</td>\n",
       "      <td>0.069764</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.045122</td>\n",
       "      <td>0.015041</td>\n",
       "      <td>0.097428</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050091</td>\n",
       "      <td>0.054187</td>\n",
       "      <td>0.049822</td>\n",
       "      <td>0.046666</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.180167</td>\n",
       "      <td>0.025469</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.046130</td>\n",
       "      <td>0.083635</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.034143</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.088752</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.054203</td>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.043288</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.012929</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.223182</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.096366</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>0.087216</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>0.049043</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>0.027486</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.219981</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.013994</td>\n",
       "      <td>0.023060</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.089897</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.085151</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023182</td>\n",
       "      <td>0.054121</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.032673</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.028171</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.229756</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.012777</td>\n",
       "      <td>0.029812</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.091454</td>\n",
       "      <td>0.011264</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026898</td>\n",
       "      <td>0.047352</td>\n",
       "      <td>0.059569</td>\n",
       "      <td>0.034744</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.177605</td>\n",
       "      <td>0.022741</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.064937</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.066926</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>0.074535</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045914</td>\n",
       "      <td>0.058971</td>\n",
       "      <td>0.054734</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.023346</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.202369</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>0.037057</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.033062</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.075492</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039399</td>\n",
       "      <td>0.065023</td>\n",
       "      <td>0.046150</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.033889</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.067845</td>\n",
       "      <td>0.013464</td>\n",
       "      <td>0.034339</td>\n",
       "      <td>0.048833</td>\n",
       "      <td>0.116042</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.016007</td>\n",
       "      <td>0.022805</td>\n",
       "      <td>0.076945</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070147</td>\n",
       "      <td>0.079576</td>\n",
       "      <td>0.075037</td>\n",
       "      <td>0.025919</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>0.036115</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.080292</td>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.038346</td>\n",
       "      <td>0.129841</td>\n",
       "      <td>0.016706</td>\n",
       "      <td>0.018952</td>\n",
       "      <td>0.042702</td>\n",
       "      <td>0.073995</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066235</td>\n",
       "      <td>0.063606</td>\n",
       "      <td>0.078850</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.056764</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.035835</td>\n",
       "      <td>0.049876</td>\n",
       "      <td>0.127155</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.086050</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067304</td>\n",
       "      <td>0.090078</td>\n",
       "      <td>0.068433</td>\n",
       "      <td>0.042912</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.071875</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.038476</td>\n",
       "      <td>0.040330</td>\n",
       "      <td>0.139357</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.015386</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>0.079491</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064060</td>\n",
       "      <td>0.073023</td>\n",
       "      <td>0.066334</td>\n",
       "      <td>0.048652</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.104424</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.089460</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>0.026675</td>\n",
       "      <td>0.015615</td>\n",
       "      <td>0.090599</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069616</td>\n",
       "      <td>0.079050</td>\n",
       "      <td>0.052863</td>\n",
       "      <td>0.036923</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.164742</td>\n",
       "      <td>0.026059</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.041585</td>\n",
       "      <td>0.088281</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>0.036007</td>\n",
       "      <td>0.025123</td>\n",
       "      <td>0.082078</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>0.053250</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.185617</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>0.026729</td>\n",
       "      <td>0.033097</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.082552</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.081751</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035842</td>\n",
       "      <td>0.058720</td>\n",
       "      <td>0.052162</td>\n",
       "      <td>0.023793</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.017082</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.167981</td>\n",
       "      <td>0.016374</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>0.055791</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>0.066707</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>0.070346</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044269</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.016374</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           a         b         c         d         e         f         g  \\\n",
       "0   0.076101  0.012865  0.045792  0.046228  0.104884  0.015700  0.019189   \n",
       "1   0.084238  0.019926  0.030426  0.038898  0.136857  0.017420  0.031261   \n",
       "2   0.071825  0.012202  0.045757  0.032723  0.119523  0.014698  0.025236   \n",
       "3   0.072251  0.027731  0.029994  0.039615  0.120921  0.016789  0.023580   \n",
       "4   0.073806  0.020368  0.031099  0.039641  0.141261  0.020368  0.020368   \n",
       "5   0.077913  0.014919  0.035749  0.044830  0.149735  0.011784  0.011496   \n",
       "6   0.072717  0.013065  0.035412  0.044990  0.150754  0.010523  0.010582   \n",
       "7   0.072608  0.015763  0.039841  0.051136  0.157130  0.013032  0.013529   \n",
       "8   0.078947  0.011501  0.035283  0.051852  0.143275  0.012086  0.020078   \n",
       "9   0.078738  0.010451  0.037253  0.053283  0.150487  0.016222  0.010708   \n",
       "10  0.126248  0.031936  0.014471  0.034431  0.096806  0.004491  0.059880   \n",
       "11  0.147611  0.024581  0.009202  0.039455  0.093407  0.011093  0.033909   \n",
       "12  0.177381  0.023302  0.005501  0.038746  0.083661  0.012693  0.049591   \n",
       "13  0.169341  0.025045  0.004566  0.032431  0.069764  0.007923  0.045122   \n",
       "14  0.180167  0.025469  0.008251  0.046130  0.083635  0.005117  0.034143   \n",
       "15  0.223182  0.024521  0.008125  0.013139  0.024229  0.003514  0.096366   \n",
       "16  0.219981  0.017919  0.004989  0.013994  0.023060  0.001795  0.089897   \n",
       "17  0.229756  0.021014  0.002522  0.012777  0.029812  0.000280  0.091454   \n",
       "18  0.177605  0.022741  0.019023  0.021790  0.064937  0.004929  0.066926   \n",
       "19  0.202369  0.022730  0.019562  0.037057  0.064196  0.005786  0.033062   \n",
       "20  0.067845  0.013464  0.034339  0.048833  0.116042  0.020020  0.016007   \n",
       "21  0.080292  0.016176  0.035354  0.038346  0.129841  0.016706  0.018952   \n",
       "22  0.056764  0.012008  0.035835  0.049876  0.127155  0.013476  0.008620   \n",
       "23  0.071875  0.011413  0.038476  0.040330  0.139357  0.012185  0.015386   \n",
       "24  0.104424  0.022121  0.015290  0.044242  0.089460  0.011386  0.026675   \n",
       "25  0.164742  0.026059  0.014590  0.041585  0.088281  0.005969  0.036007   \n",
       "26  0.185617  0.019561  0.014375  0.026729  0.033097  0.007969  0.082552   \n",
       "27  0.167981  0.016374  0.018799  0.024864  0.055791  0.009096  0.066707   \n",
       "\n",
       "           h         i         j  ...         r         s         t         u  \\\n",
       "0   0.043829  0.074139  0.001744  ...  0.077846  0.061491  0.080026  0.025949   \n",
       "1   0.027443  0.075409  0.002625  ...  0.090204  0.071710  0.077556  0.030665   \n",
       "2   0.023572  0.094842  0.002496  ...  0.054077  0.088186  0.080422  0.029118   \n",
       "3   0.059045  0.065271  0.001509  ...  0.059234  0.073382  0.093567  0.024335   \n",
       "4   0.056943  0.065046  0.003285  ...  0.072492  0.059571  0.095488  0.024967   \n",
       "5   0.012613  0.072003  0.002126  ...  0.074741  0.082093  0.070561  0.054452   \n",
       "6   0.011528  0.071416  0.003015  ...  0.076914  0.078333  0.065681  0.050902   \n",
       "7   0.014397  0.085516  0.004344  ...  0.082040  0.066526  0.061065  0.042696   \n",
       "8   0.019493  0.089864  0.003899  ...  0.077778  0.072320  0.063353  0.043860   \n",
       "9   0.015517  0.069377  0.002308  ...  0.075083  0.071621  0.077584  0.053475   \n",
       "10  0.013972  0.104790  0.003992  ...  0.076846  0.068862  0.046906  0.042415   \n",
       "11  0.018530  0.100340  0.005294  ...  0.046641  0.081306  0.050800  0.040590   \n",
       "12  0.018666  0.087158  0.007388  ...  0.052067  0.047587  0.049866  0.048530   \n",
       "13  0.015041  0.097428  0.006647  ...  0.050091  0.054187  0.049822  0.046666   \n",
       "14  0.020840  0.088752  0.009064  ...  0.056915  0.054203  0.050240  0.043288   \n",
       "15  0.018775  0.087216  0.001244  ...  0.017677  0.049043  0.054496  0.027486   \n",
       "16  0.016884  0.085151  0.000700  ...  0.023182  0.054121  0.044872  0.032673   \n",
       "17  0.011264  0.070384  0.001793  ...  0.026898  0.047352  0.059569  0.034744   \n",
       "18  0.019023  0.074535  0.001902  ...  0.045914  0.058971  0.054734  0.027756   \n",
       "19  0.006750  0.075492  0.002342  ...  0.039399  0.065023  0.046150  0.027828   \n",
       "20  0.022805  0.076945  0.002412  ...  0.070147  0.079576  0.075037  0.025919   \n",
       "21  0.042702  0.073995  0.004463  ...  0.066235  0.063606  0.078850  0.027634   \n",
       "22  0.007303  0.086050  0.002786  ...  0.067304  0.090078  0.068433  0.042912   \n",
       "23  0.018410  0.079491  0.004150  ...  0.064060  0.073023  0.066334  0.048652   \n",
       "24  0.015615  0.090599  0.005368  ...  0.069616  0.079050  0.052863  0.036923   \n",
       "25  0.025123  0.082078  0.007256  ...  0.053640  0.048802  0.053250  0.047437   \n",
       "26  0.014070  0.081751  0.000229  ...  0.035842  0.058720  0.052162  0.023793   \n",
       "27  0.011522  0.070346  0.000606  ...  0.044269  0.052759  0.061249  0.036992   \n",
       "\n",
       "           v         w         x         y         z  language  \n",
       "0   0.009158  0.014174  0.000654  0.020061  0.000436        en  \n",
       "1   0.013483  0.013960  0.002028  0.010739  0.000597        en  \n",
       "2   0.018026  0.011925  0.000555  0.018026  0.000555        en  \n",
       "3   0.004905  0.019619  0.006037  0.017544  0.001698        en  \n",
       "4   0.010731  0.023872  0.003066  0.014893  0.000657        en  \n",
       "5   0.010631  0.004541  0.003892  0.005334  0.000468        fr  \n",
       "6   0.012711  0.002601  0.004966  0.004848  0.000118        fr  \n",
       "7   0.015142  0.000745  0.005089  0.004965  0.001986        fr  \n",
       "8   0.014035  0.000390  0.003314  0.005263  0.001170        fr  \n",
       "9   0.014299  0.000705  0.003911  0.003655  0.000834        fr  \n",
       "10  0.003992  0.006487  0.001497  0.009481  0.001497        id  \n",
       "11  0.008068  0.005042  0.001387  0.013614  0.000630        id  \n",
       "12  0.001572  0.004087  0.000236  0.014579  0.000236        id  \n",
       "13  0.002216  0.001813  0.000201  0.011750  0.000537        id  \n",
       "14  0.003005  0.006237  0.000309  0.012929  0.001137        id  \n",
       "15  0.002452  0.012371  0.000512  0.020130  0.001061        tl  \n",
       "16  0.000639  0.009096  0.000304  0.028171  0.000152        tl  \n",
       "17  0.001065  0.014290  0.000056  0.019725  0.000056        tl  \n",
       "18  0.005102  0.008214  0.000865  0.023346  0.002681        tl  \n",
       "19  0.004822  0.005786  0.000413  0.033889  0.003031        tl  \n",
       "20  0.014670  0.036115  0.005635  0.013091  0.000417        en  \n",
       "21  0.012988  0.014881  0.002119  0.013302  0.001491        en  \n",
       "22  0.013852  0.028909  0.009298  0.005157  0.000414        fr  \n",
       "23  0.013598  0.002892  0.004282  0.003355  0.001192        fr  \n",
       "24  0.016591  0.033669  0.004880  0.009597  0.000488        id  \n",
       "25  0.004681  0.004603  0.000468  0.014824  0.000585        id  \n",
       "26  0.004804  0.028369  0.003394  0.017082  0.000419        tl  \n",
       "27  0.001819  0.016374  0.000606  0.018193  0.000606        tl  \n",
       "\n",
       "[28 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_df, test_df]).reset_index(drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDF = df.iloc[:, :-1]\n",
    "targetSR = df['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(featureDF, targetSR,\n",
    "                                                    stratify=targetSR,\n",
    "                                                    train_size = 0.8,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (22, 26), y_train : (22,)\n",
      "X_test : (6, 26), y_test : (6,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train : {X_train.shape}, y_train : {y_train.shape}\")\n",
    "print(f\"X_test : {X_test.shape}, y_test : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 결정 트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {'max_depth' : [2, 4, 6],\n",
    "             'min_samples_leaf': [2, 3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 4, 6], &#x27;min_samples_leaf&#x27;: [2, 3, 4]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 4, 6], &#x27;min_samples_leaf&#x27;: [2, 3, 4]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [2, 4, 6], 'min_samples_leaf': [2, 3, 4]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "dt_grid_search = GridSearchCV(estimator=dt, param_grid=dt_params,\n",
    "                              cv=5, scoring='accuracy')\n",
    "\n",
    "# 그리드 탐색 수행\n",
    "dt_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'min_samples_leaf': 2}\n",
      "train score : 1.0\n",
      "test score : 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "dt_best = dt_grid_search.best_estimator_\n",
    "\n",
    "print(dt_grid_search.best_params_)\n",
    "\n",
    "print(f\"train score : {dt_best.score(X_train, y_train)}\")\n",
    "print(f\"test score : {dt_best.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 오분류표\n",
      "[[5 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 5 0]\n",
      " [0 0 0 6]]\n",
      "\n",
      "테스트 세트 오분류표\n",
      "[[1 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "dt_pred_train = dt_best.predict(X_train)\n",
    "dt_pred_test = dt_best.predict(X_test)\n",
    "\n",
    "print(f\"훈련 세트 오분류표\\n{confusion_matrix(y_train, dt_pred_train)}\")\n",
    "print()\n",
    "print(f\"테스트 세트 오분류표\\n{confusion_matrix(y_test, dt_pred_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_evaluation(pred_train, pred_test):\n",
    "    # 정밀도\n",
    "    print(f\"훈련 세트 정밀도 {df['language'].unique()} : {precision_score(y_train, pred_train, zero_division=0, average=None)}\")\n",
    "    print(f\"테스트 세트 정밀도 {df['language'].unique()} : {precision_score(y_test, pred_test, zero_division=0, average=None)}\")\n",
    "    print()\n",
    "\n",
    "    # 민감도(재현율)\n",
    "    print(f\"훈련 세트 민감도 {df['language'].unique()} : {recall_score(y_train, pred_train, zero_division=0, average=None)}\")\n",
    "    print(f\"테스트 세트 민감도 {df['language'].unique()} : {recall_score(y_test, pred_test, zero_division=0, average=None)}\")\n",
    "    print()\n",
    "\n",
    "    # F1 스코어\n",
    "    print(f\"훈련 세트 F1 스코어 {df['language'].unique()} : {f1_score(y_train, pred_train, zero_division=0, average=None)}\")\n",
    "    print(f\"테스트 세트 F1 스코어 {df['language'].unique()} : {f1_score(y_test, pred_test, zero_division=0, average=None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정밀도 ['en' 'fr' 'id' 'tl'] : [1. 1. 1. 1.]\n",
      "테스트 세트 정밀도 ['en' 'fr' 'id' 'tl'] : [1.  0.5 1.  1. ]\n",
      "\n",
      "훈련 세트 민감도 ['en' 'fr' 'id' 'tl'] : [1. 1. 1. 1.]\n",
      "테스트 세트 민감도 ['en' 'fr' 'id' 'tl'] : [0.5 1.  1.  1. ]\n",
      "\n",
      "훈련 세트 F1 스코어 ['en' 'fr' 'id' 'tl'] : [1. 1. 1. 1.]\n",
      "테스트 세트 F1 스코어 ['en' 'fr' 'id' 'tl'] : [0.66666667 0.66666667 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "display_evaluation(dt_pred_train, dt_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"416pt\" height=\"433pt\"\n",
       " viewBox=\"0.00 0.00 416.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-429 412,-429 412,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M183,-425C183,-425 83,-425 83,-425 77,-425 71,-419 71,-413 71,-413 71,-354 71,-354 71,-348 77,-342 83,-342 83,-342 183,-342 183,-342 189,-342 195,-348 195,-354 195,-354 195,-413 195,-413 195,-419 189,-425 183,-425\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-407.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">e &lt;= 0.067</text>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-392.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.748</text>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-377.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-362.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 6, 5, 6]</text>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-347.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = b</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#d739e5\" stroke=\"black\" d=\"M112,-298.5C112,-298.5 12,-298.5 12,-298.5 6,-298.5 0,-292.5 0,-286.5 0,-286.5 0,-242.5 0,-242.5 0,-236.5 6,-230.5 12,-230.5 12,-230.5 112,-230.5 112,-230.5 118,-230.5 124,-236.5 124,-242.5 124,-242.5 124,-286.5 124,-286.5 124,-292.5 118,-298.5 112,-298.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"62\" y=\"-281.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"62\" y=\"-266.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n",
       "<text text-anchor=\"middle\" x=\"62\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 0, 6]</text>\n",
       "<text text-anchor=\"middle\" x=\"62\" y=\"-236.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = d</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.17,-341.58C101.68,-330.88 94.66,-319.32 88.11,-308.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91.21,-306.89 83.03,-300.16 85.23,-310.52 91.21,-306.89\"/>\n",
       "<text text-anchor=\"middle\" x=\"76.3\" y=\"-317.34\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#eefded\" stroke=\"black\" d=\"M254,-306C254,-306 154,-306 154,-306 148,-306 142,-300 142,-294 142,-294 142,-235 142,-235 142,-229 148,-223 154,-223 154,-223 254,-223 254,-223 260,-223 266,-229 266,-235 266,-235 266,-294 266,-294 266,-300 260,-306 254,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"204\" y=\"-288.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">k &lt;= 0.005</text>\n",
       "<text text-anchor=\"middle\" x=\"204\" y=\"-273.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.664</text>\n",
       "<text text-anchor=\"middle\" x=\"204\" y=\"-258.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n",
       "<text text-anchor=\"middle\" x=\"204\" y=\"-243.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 6, 5, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"204\" y=\"-228.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = b</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.83,-341.58C162.89,-333.25 168.26,-324.39 173.49,-315.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.32,-317.86 178.52,-307.49 170.34,-314.23 176.32,-317.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"185.24\" y=\"-324.68\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#47e539\" stroke=\"black\" d=\"M183,-179.5C183,-179.5 83,-179.5 83,-179.5 77,-179.5 71,-173.5 71,-167.5 71,-167.5 71,-123.5 71,-123.5 71,-117.5 77,-111.5 83,-111.5 83,-111.5 183,-111.5 183,-111.5 189,-111.5 195,-117.5 195,-123.5 195,-123.5 195,-167.5 195,-167.5 195,-173.5 189,-179.5 183,-179.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-162.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-147.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-132.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-117.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = b</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.17,-222.58C172.68,-211.88 165.66,-200.32 159.11,-189.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"162.21,-187.89 154.03,-181.16 156.23,-191.52 162.21,-187.89\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M325,-187C325,-187 225,-187 225,-187 219,-187 213,-181 213,-175 213,-175 213,-116 213,-116 213,-110 219,-104 225,-104 225,-104 325,-104 325,-104 331,-104 337,-110 337,-116 337,-116 337,-175 337,-175 337,-181 331,-187 325,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-169.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">o &lt;= 0.063</text>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-154.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-139.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-124.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0, 5, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-109.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = a</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M228.83,-222.58C233.89,-214.25 239.26,-205.39 244.49,-196.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"247.32,-198.86 249.52,-188.49 241.34,-195.23 247.32,-198.86\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M254,-68C254,-68 154,-68 154,-68 148,-68 142,-62 142,-56 142,-56 142,-12 142,-12 142,-6 148,0 154,0 154,0 254,0 254,0 260,0 266,-6 266,-12 266,-12 266,-56 266,-56 266,-62 260,-68 254,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"204\" y=\"-50.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"204\" y=\"-35.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"204\" y=\"-20.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 5, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"204\" y=\"-5.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = c</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M248.56,-103.73C243.06,-95.24 237.25,-86.28 231.71,-77.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"234.79,-76.06 226.41,-69.57 228.92,-79.86 234.79,-76.06\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M396,-68C396,-68 296,-68 296,-68 290,-68 284,-62 284,-56 284,-56 284,-12 284,-12 284,-6 290,0 296,0 296,0 396,0 396,0 402,0 408,-6 408,-12 408,-12 408,-56 408,-56 408,-62 402,-68 396,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-50.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-35.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-20.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-5.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = a</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301.44,-103.73C306.94,-95.24 312.75,-86.28 318.29,-77.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"321.08,-79.86 323.59,-69.57 315.21,-76.06 321.08,-79.86\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x11fe56550>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) DT모델을 dot포맷의 파일로 저장 ==> export_graphviz()\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "export_graphviz(dt_best, out_file='tree.dot',\n",
    "                class_names=df.columns,\n",
    "                feature_names=dt_best.feature_names_in_,\n",
    "                impurity=True, filled=True, rounded=True)\n",
    "\n",
    "# (2) dot파일 출력\n",
    "# 파일에서 데이터 읽어오기\n",
    "with open('tree.dot') as f:\n",
    "    dot_data = f.read()\n",
    "\n",
    "# 화면에 출력하기\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {'solver' : ['liblinear', 'lbfgs'],\n",
    "             'max_iter': [100, 200, 300],\n",
    "             'C': [1, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 0.1, 0.01], &#x27;max_iter&#x27;: [100, 200, 300],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 0.1, 0.01], &#x27;max_iter&#x27;: [100, 200, 300],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 0.1, 0.01], 'max_iter': [100, 200, 300],\n",
       "                         'solver': ['liblinear', 'lbfgs']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "lr_grid_search = GridSearchCV(estimator=lr, param_grid=lr_params,\n",
    "                              cv=5, scoring='accuracy')\n",
    "\n",
    "# 그리드 탐색 수행\n",
    "lr_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "train score : 0.5454545454545454\n",
      "test score : 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "lr_best = lr_grid_search.best_estimator_\n",
    "\n",
    "print(lr_grid_search.best_params_)\n",
    "\n",
    "print(f\"train score : {lr_best.score(X_train, y_train)}\")\n",
    "print(f\"test score : {lr_best.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 5 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 0 5]\n",
      " [0 0 0 6]]\n",
      "[[0 2 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "lr_pred_train = lr_best.predict(X_train)\n",
    "lr_pred_test = lr_best.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_train, lr_pred_train))\n",
    "print(confusion_matrix(y_test, lr_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정밀도 ['en' 'fr' 'id' 'tl'] : [0.         0.54545455 0.         0.54545455]\n",
      "테스트 세트 정밀도 ['en' 'fr' 'id' 'tl'] : [0.   0.25 0.   0.5 ]\n",
      "\n",
      "훈련 세트 민감도 ['en' 'fr' 'id' 'tl'] : [0. 1. 0. 1.]\n",
      "테스트 세트 민감도 ['en' 'fr' 'id' 'tl'] : [0. 1. 0. 1.]\n",
      "\n",
      "훈련 세트 F1 스코어 ['en' 'fr' 'id' 'tl'] : [0.         0.70588235 0.         0.70588235]\n",
      "테스트 세트 F1 스코어 ['en' 'fr' 'id' 'tl'] : [0.         0.4        0.         0.66666667]\n"
     ]
    }
   ],
   "source": [
    "display_evaluation(lr_pred_train, lr_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'max_depth' : [2, 4, 6],\n",
    "             'min_samples_leaf': [2, 3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 4, 6], &#x27;min_samples_leaf&#x27;: [2, 3, 4]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 4, 6], &#x27;min_samples_leaf&#x27;: [2, 3, 4]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [2, 4, 6], 'min_samples_leaf': [2, 3, 4]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "rf_grid_search = GridSearchCV(estimator=rf, param_grid=rf_params,\n",
    "                              cv=5, scoring='accuracy')\n",
    "\n",
    "# 그리드 탐색 수행\n",
    "rf_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'min_samples_leaf': 2}\n",
      "train score : 1.0\n",
      "test score : 1.0\n"
     ]
    }
   ],
   "source": [
    "rf_best = rf_grid_search.best_estimator_\n",
    "\n",
    "print(rf_grid_search.best_params_)\n",
    "\n",
    "print(f\"train score : {rf_best.score(X_train, y_train)}\")\n",
    "print(f\"test score : {rf_best.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 5 0]\n",
      " [0 0 0 6]]\n",
      "[[2 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "rf_pred_train = rf_best.predict(X_train)\n",
    "rf_pred_test = rf_best.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_train, rf_pred_train))\n",
    "print(confusion_matrix(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정밀도 ['en' 'fr' 'id' 'tl'] : [1. 1. 1. 1.]\n",
      "테스트 세트 정밀도 ['en' 'fr' 'id' 'tl'] : [1. 1. 1. 1.]\n",
      "\n",
      "훈련 세트 민감도 ['en' 'fr' 'id' 'tl'] : [1. 1. 1. 1.]\n",
      "테스트 세트 민감도 ['en' 'fr' 'id' 'tl'] : [1. 1. 1. 1.]\n",
      "\n",
      "훈련 세트 F1 스코어 ['en' 'fr' 'id' 'tl'] : [1. 1. 1. 1.]\n",
      "테스트 세트 F1 스코어 ['en' 'fr' 'id' 'tl'] : [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "display_evaluation(rf_pred_train, rf_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          en       1.00      1.00      1.00         5\n",
      "          fr       1.00      1.00      1.00         6\n",
      "          id       1.00      1.00      1.00         5\n",
      "          tl       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "테스트 세트 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          en       1.00      1.00      1.00         2\n",
      "          fr       1.00      1.00      1.00         1\n",
      "          id       1.00      1.00      1.00         2\n",
      "          tl       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('훈련 세트 분류 리포트')\n",
    "print(classification_report(y_train, rf_pred_train))\n",
    "\n",
    "print('테스트 세트 분류 리포트')\n",
    "print(classification_report(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 중요한 변수만 다시 넣어서 로지스틱 돌려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 0.354),\n",
       " ('k', 0.342),\n",
       " ('o', 0.304),\n",
       " ('a', 0.0),\n",
       " ('b', 0.0),\n",
       " ('c', 0.0),\n",
       " ('d', 0.0),\n",
       " ('f', 0.0),\n",
       " ('g', 0.0),\n",
       " ('h', 0.0),\n",
       " ('i', 0.0),\n",
       " ('j', 0.0),\n",
       " ('l', 0.0),\n",
       " ('m', 0.0),\n",
       " ('n', 0.0),\n",
       " ('p', 0.0),\n",
       " ('q', 0.0),\n",
       " ('r', 0.0),\n",
       " ('s', 0.0),\n",
       " ('t', 0.0),\n",
       " ('u', 0.0),\n",
       " ('v', 0.0),\n",
       " ('w', 0.0),\n",
       " ('x', 0.0),\n",
       " ('y', 0.0),\n",
       " ('z', 0.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_dict = {key : value for key, value in zip(dt_best.feature_names_in_, dt_best.feature_importances_.round(3))}\n",
    "\n",
    "sorted(feature_importances_dict.items(), key = lambda x : x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> n, y, k가 중요한 변수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_featureDF = df.loc[:, ['n','y','k']]\n",
    "targetSR = df['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_featureDF, targetSR,\n",
    "                                                    stratify=targetSR,\n",
    "                                                    train_size = 0.8,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (22, 3), y_train : (22,)\n",
      "X_test : (6, 3), y_test : (6,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train : {X_train.shape}, y_train : {y_train.shape}\")\n",
    "print(f\"X_test : {X_test.shape}, y_test : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {'solver' : ['liblinear', 'lbfgs'],\n",
    "             'max_iter': [100, 200, 300],\n",
    "             'C': [1, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 0.1, 0.01], &#x27;max_iter&#x27;: [100, 200, 300],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 0.1, 0.01], &#x27;max_iter&#x27;: [100, 200, 300],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 0.1, 0.01], 'max_iter': [100, 200, 300],\n",
       "                         'solver': ['liblinear', 'lbfgs']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "lr_grid_search = GridSearchCV(estimator=lr, param_grid=lr_params,\n",
    "                              cv=5, scoring='accuracy')\n",
    "\n",
    "# 그리드 탐색 수행\n",
    "lr_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "train score : 0.5454545454545454\n",
      "test score : 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "lr_best = lr_grid_search.best_estimator_\n",
    "\n",
    "print(lr_grid_search.best_params_)\n",
    "\n",
    "print(f\"train score : {lr_best.score(X_train, y_train)}\")\n",
    "print(f\"test score : {lr_best.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 5 0 0]\n",
      " [0 6 0 0]\n",
      " [0 1 0 4]\n",
      " [0 0 0 6]]\n",
      "[[0 2 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "lr_pred_train = lr_best.predict(X_train)\n",
    "lr_pred_test = lr_best.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_train, lr_pred_train))\n",
    "print(confusion_matrix(y_test, lr_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정밀도 ['en' 'fr' 'id' 'tl'] : [0.  0.5 0.  0.6]\n",
      "테스트 세트 정밀도 ['en' 'fr' 'id' 'tl'] : [0.   0.25 0.   0.5 ]\n",
      "\n",
      "훈련 세트 민감도 ['en' 'fr' 'id' 'tl'] : [0. 1. 0. 1.]\n",
      "테스트 세트 민감도 ['en' 'fr' 'id' 'tl'] : [0. 1. 0. 1.]\n",
      "\n",
      "훈련 세트 F1 스코어 ['en' 'fr' 'id' 'tl'] : [0.         0.66666667 0.         0.75      ]\n",
      "테스트 세트 F1 스코어 ['en' 'fr' 'id' 'tl'] : [0.         0.4        0.         0.66666667]\n"
     ]
    }
   ],
   "source": [
    "display_evaluation(lr_pred_train, lr_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 성능 개선이 없다. 아마 더 많은 데이터를 수집해야 할 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
