{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 데이터셋과 모델과 학습\n",
    "- iris.csv ==> 사용자 정의 데이터셋\n",
    "- DNN 모델 ==> 사용자 정의 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import F1Score\n",
    "from torchinfo import summary\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder      # 타겟 컬럼 수치화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "DATA_FILE = '../../../Data/iris.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV ==> DataFrame\n",
    "irisDF = pd.read_csv(DATA_FILE)\n",
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 컬럼 수치화 ==> LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(irisDF['variety'])\n",
    "irisDF['variety'] = encoder.transform(irisDF['variety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 사용자 정의 데이터셋 클래스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 클래스 목적 : 학습용 데이터셋 텐서화 및 전처리\n",
    "# 클래스 이름 : CustomDataSet\n",
    "# 부모 클래스 : torch.utils.data.Dataset\n",
    "# 매개   변수 : featureDF, targetDF\n",
    "# ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    # 데이터 로딩 및 전처리 진행과 인스턴스 생성 메서드\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        super().__init__()\n",
    "        self.featureDF = featureDF\n",
    "        self.targetDF = targetDF\n",
    "        self.n_rows = featureDF.shape[0]\n",
    "        self.n_features = featureDF.shape[1]\n",
    "\n",
    "    # 데이터의 개수 반환 메서드\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "\n",
    "    # 특정 index의 데이터와 타겟 반환 메서드 => Tensor 반환!!!\n",
    "    def __getitem__(self, idx):\n",
    "        featureTS = torch.FloatTensor(self.featureDF.iloc[idx].values)\n",
    "        targetTS = torch.FloatTensor(self.targetDF.iloc[idx].values)\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 인스턴스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF => (150, 4), targetDF => (150, 1)\n"
     ]
    }
   ],
   "source": [
    "featureDF, targetDF = irisDF[irisDF.columns[:-1]], irisDF[[irisDF.columns[-1]]]\n",
    "\n",
    "print(f'featureDF => {featureDF.shape}, targetDF => {targetDF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRIS 데이터셋 인스턴스 생성\n",
    "irisDS = CustomDataset(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 150)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IRIS 데이터셋 속성\n",
    "irisDS.n_features, irisDS.n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor([0.]))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 데이터로더 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 것 : Dataset 인스턴스, Batch_size=1[기본값]\n",
    "irisDL = DataLoader(irisDS, batch_size=10)\n",
    "# 지정한 배치사이즈 만큼 데이터셋에서 꺼내옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4]) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "for dataTS, targetTS in irisDL:\n",
    "    print(dataTS.shape, targetTS.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 모델 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 모델  이름 : CustomModel\n",
    "# 부모클래스 : nn.Module\n",
    "# 매개  변수 : None\n",
    "# 모델  구조\n",
    "# - 입력층   : 입력 4개,    출력 10개    AF ReLU -> LeakyReLU\n",
    "# - 은닉층   : 입력 10개,   출력 30개    AF ReLU -> LeakyReLU\n",
    "# - 출력층   : 입력 30개,   출력  3개    AF 분류 - 다중 softmax\n",
    "# -------------------------------------------------------------\n",
    "class CustomModel(nn.Module):\n",
    "    # 모델 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_layer = nn.Linear(4, 10)\n",
    "        self.hidden_layer = nn.Linear(10, 30)\n",
    "        self.out_layer = nn.Linear(30, 3) # 붓꽃 종류가 3종류라 출력이 3개\n",
    "\n",
    "    # 순방향 학습 메서드\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.in_layer(x))\n",
    "        y = F.relu(self.hidden_layer(y))\n",
    "        # return F.softmax(self.out_layer(y))\n",
    "        return self.out_layer(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 학습 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (in_layer): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (hidden_layer): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (out_layer): Linear(in_features=30, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "CustomModel                              --\n",
       "├─Linear: 1-1                            50\n",
       "├─Linear: 1-2                            330\n",
       "├─Linear: 1-3                            93\n",
       "=================================================================\n",
       "Total params: 473\n",
       "Trainable params: 473\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model = CustomModel()\n",
    "print(model)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optim = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(1.0655, grad_fn=<DivBackward0>),\n",
       "  tensor(1.0245, grad_fn=<DivBackward0>),\n",
       "  tensor(1.0001, grad_fn=<DivBackward0>),\n",
       "  tensor(0.9755, grad_fn=<DivBackward0>),\n",
       "  tensor(0.9518, grad_fn=<DivBackward0>),\n",
       "  tensor(0.9277, grad_fn=<DivBackward0>),\n",
       "  tensor(0.9031, grad_fn=<DivBackward0>),\n",
       "  tensor(0.8792, grad_fn=<DivBackward0>),\n",
       "  tensor(0.8574, grad_fn=<DivBackward0>),\n",
       "  tensor(0.8354, grad_fn=<DivBackward0>),\n",
       "  tensor(0.8132, grad_fn=<DivBackward0>),\n",
       "  tensor(0.7912, grad_fn=<DivBackward0>),\n",
       "  tensor(0.7693, grad_fn=<DivBackward0>),\n",
       "  tensor(0.7476, grad_fn=<DivBackward0>),\n",
       "  tensor(0.7260, grad_fn=<DivBackward0>),\n",
       "  tensor(0.7049, grad_fn=<DivBackward0>),\n",
       "  tensor(0.6816, grad_fn=<DivBackward0>),\n",
       "  tensor(0.6562, grad_fn=<DivBackward0>),\n",
       "  tensor(0.6320, grad_fn=<DivBackward0>),\n",
       "  tensor(0.6106, grad_fn=<DivBackward0>),\n",
       "  tensor(0.5911, grad_fn=<DivBackward0>),\n",
       "  tensor(0.5720, grad_fn=<DivBackward0>),\n",
       "  tensor(0.5550, grad_fn=<DivBackward0>),\n",
       "  tensor(0.5390, grad_fn=<DivBackward0>),\n",
       "  tensor(0.5241, grad_fn=<DivBackward0>),\n",
       "  tensor(0.5103, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4975, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4856, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4746, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4644, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4551, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4459, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4375, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4297, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4220, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4151, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4083, grad_fn=<DivBackward0>),\n",
       "  tensor(0.4017, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3954, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3888, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3829, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3770, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3709, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3655, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3602, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3550, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3500, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3452, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3405, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3359, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3316, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3271, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3228, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3186, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3145, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3105, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3066, grad_fn=<DivBackward0>),\n",
       "  tensor(0.3027, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2989, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2953, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2915, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2879, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2843, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2809, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2774, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2741, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2708, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2676, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2644, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2612, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2581, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2552, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2522, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2492, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2464, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2435, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2407, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2380, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2352, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2326, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2300, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2275, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2250, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2225, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2201, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2177, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2154, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2131, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2108, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2086, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2065, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2043, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2022, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2002, grad_fn=<DivBackward0>),\n",
       "  tensor(0.1982, grad_fn=<DivBackward0>),\n",
       "  tensor(0.1962, grad_fn=<DivBackward0>),\n",
       "  tensor(0.1943, grad_fn=<DivBackward0>),\n",
       "  tensor(0.1924, grad_fn=<DivBackward0>),\n",
       "  tensor(0.1905, grad_fn=<DivBackward0>),\n",
       "  tensor(0.1887, grad_fn=<DivBackward0>)],\n",
       " [tensor(0.3333),\n",
       "  tensor(0.3333),\n",
       "  tensor(0.3333),\n",
       "  tensor(0.3667),\n",
       "  tensor(0.5667),\n",
       "  tensor(0.5733),\n",
       "  tensor(0.7600),\n",
       "  tensor(0.7933),\n",
       "  tensor(0.7200),\n",
       "  tensor(0.7000),\n",
       "  tensor(0.6933),\n",
       "  tensor(0.6800),\n",
       "  tensor(0.6800),\n",
       "  tensor(0.6800),\n",
       "  tensor(0.6800),\n",
       "  tensor(0.6867),\n",
       "  tensor(0.7000),\n",
       "  tensor(0.7067),\n",
       "  tensor(0.6933),\n",
       "  tensor(0.7067),\n",
       "  tensor(0.7267),\n",
       "  tensor(0.7667),\n",
       "  tensor(0.7933),\n",
       "  tensor(0.8000),\n",
       "  tensor(0.8067),\n",
       "  tensor(0.8133),\n",
       "  tensor(0.8333),\n",
       "  tensor(0.8467),\n",
       "  tensor(0.8533),\n",
       "  tensor(0.8667),\n",
       "  tensor(0.8800),\n",
       "  tensor(0.8800),\n",
       "  tensor(0.8800),\n",
       "  tensor(0.8867),\n",
       "  tensor(0.9000),\n",
       "  tensor(0.9000),\n",
       "  tensor(0.9067),\n",
       "  tensor(0.9067),\n",
       "  tensor(0.9067),\n",
       "  tensor(0.9067),\n",
       "  tensor(0.9200),\n",
       "  tensor(0.9333),\n",
       "  tensor(0.9267),\n",
       "  tensor(0.9333),\n",
       "  tensor(0.9333),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9333),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9400),\n",
       "  tensor(0.9467),\n",
       "  tensor(0.9467),\n",
       "  tensor(0.9467),\n",
       "  tensor(0.9467),\n",
       "  tensor(0.9467),\n",
       "  tensor(0.9467),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9533),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600),\n",
       "  tensor(0.9600)])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치크기만큼 데이터와 타겟 추출해서 학습 진행\n",
    "TS_loss, TS_score = [], []\n",
    "for epoch in range(100):\n",
    "    loss_total, score_total = 0, 0\n",
    "    for dataTS, targetTS in irisDL:\n",
    "\n",
    "        # 배치크기 만큼의 학습 데이터\n",
    "        # print(dataTS.shape, targetTS.shape, targetTS.dtype)\n",
    "        targetTS1D = targetTS.reshape(-1).long()\n",
    "\n",
    "        # 배치크기만큼 학습 진행\n",
    "        pred_y = model(dataTS)\n",
    "        # print(pred_y.shape, targetTS.reshape(-1).shape)\n",
    " \n",
    "        # 손실 계산\n",
    "        loss = nn.CrossEntropyLoss()(pred_y, targetTS1D)\n",
    "        loss_total += loss\n",
    "\n",
    "        pred_y_label = torch.argmax(pred_y, dim=1)\n",
    "        score = F1Score(task='multiclass', num_classes=3)(pred_y_label, targetTS1D)\n",
    "        score_total += score\n",
    "\n",
    "        adam_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        adam_optim.step()\n",
    "\n",
    "    TS_loss.append(loss_total/len(irisDL))\n",
    "    TS_score.append(score_total/len(irisDL))\n",
    "\n",
    "TS_loss, TS_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from TorchTrainTest import training, testing\n",
    "# testing(irisDL, model, is_reg=False, is_bin=False, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
