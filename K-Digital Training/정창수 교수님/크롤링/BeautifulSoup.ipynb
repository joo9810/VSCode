{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup 첫 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"head-title\" id=\"hot-articles-head-title\">\n",
      "      \n",
      "      \n",
      "      중고거래 인기매물\n",
      "  </h1>\n",
      "중고거래 인기매물\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('https://www.daangn.com/hot_articles')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "print(bs.h1)\n",
    "print(bs.h1.string.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup 기초 #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_example = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>BeautifulSoup 활용</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1 id=\"heading\">Heading 1</h1>\n",
    "    <p>Paragraph</p>\n",
    "    <span class=\"red\">BeautifulSoup Library Examples!</span>\n",
    "    <div id=\"link\">\n",
    "        <a class=\"external_link\" href=\"www.google.com\">google</a>\n",
    "\n",
    "        <div id=\"class1\">\n",
    "            <p id=\"first\">class1's first paragraph</p>\n",
    "            <a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
    "\n",
    "            <p id=\"second\">class1's second paragraph</p>\n",
    "            <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
    "            <p id=\"third\">class1's third paragraph</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    <div id=\"text_id2\">\n",
    "        Example page\n",
    "        <p>g</p>\n",
    "    </div>\n",
    "    <h1 id=\"footer\">Footer</h1>\n",
    "</body>\n",
    "</html>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>BeautifulSoup 활용</title>\n",
      "BeautifulSoup 활용\n",
      "BeautifulSoup 활용\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_example, 'html.parser')\n",
    "\n",
    "print(soup.title) # <title> 태그 전체를 가져옴\n",
    "print(soup.title.string) # <title> 태그의 텍스트만 리턴\n",
    "print(soup.title.get_text()) # .string, .text(예전 버전)와 동일한 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "<title>BeautifulSoup 활용</title>\n",
      "</head>\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<h1 id=\"heading\">Heading 1</h1>\n",
      "<p>Paragraph</p>\n",
      "<span class=\"red\">BeautifulSoup Library Examples!</span>\n",
      "<div id=\"link\">\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "</div>\n",
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n",
      "<h1 id=\"footer\">Footer</h1>\n",
      "</body>\n"
     ]
    }
   ],
   "source": [
    "print(soup.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"heading\">Heading 1</h1>\n",
      "Heading 1\n"
     ]
    }
   ],
   "source": [
    "print(soup.h1)\n",
    "print(soup.h1.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "google\n",
      "www.google.com\n",
      "www.google.com\n"
     ]
    }
   ],
   "source": [
    "print(soup.a)               # <a> 태그 전체 추출\n",
    "print(soup.a.string)        # <a> 태그 내부의 텍스트 추출\n",
    "print(soup.a['href'])       # <a> 태그 내부의 href 속성의 url을 추출\n",
    "print(soup.a.get('href'))   # soup.a['href']와 동일 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup 기초: find() 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div id=\"link\">\n",
       "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
       "<div id=\"class1\">\n",
       "<p id=\"first\">class1's first paragraph</p>\n",
       "<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
       "<p id=\"second\">class1's second paragraph</p>\n",
       "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
       "<p id=\"third\">class1's third paragraph</p>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_example, 'html.parser')\n",
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('div', {'id': 'text_id2'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Example page\n",
      "        g\n",
      "\n"
     ]
    }
   ],
   "source": [
    "div_text = soup.find('div', {'id': 'text_id2'})\n",
    "print(div_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# '\\n   Example page\\n  <p>g<\\p>\\n'\n",
    "print(div_text.string) # None 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "/pages/page1.html\n",
      "/pages/page1.html\n",
      "Page1\n"
     ]
    }
   ],
   "source": [
    "href_link = soup.find('a', {'class': 'internal_link'}) # 딕셔너리 형태\n",
    "href_link = soup.find('a', class_='internal_link') # class_사용: class는 파이썬 예약어\n",
    "\n",
    "print(href_link)                # <a class=\"internal_link\", ...>\n",
    "print(href_link['href'])        # <a>태그 내부 href 속성의 값(url)을 추출\n",
    "print(href_link.get('href'))    # ['href']와 동일 기능\n",
    "print(href_link.text)           # <a> Page1 </a>태그 내부의 텍스트 (Page1) 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "href_link.attrs:  {'class': ['internal_link'], 'href': '/pages/page1.html'}\n",
      "class 속성값:  ['internal_link']\n",
      "values(): dict_values([['internal_link'], '/pages/page1.html'])\n",
      "values[0]: ['internal_link'], values[1]: /pages/page1.html\n"
     ]
    }
   ],
   "source": [
    "print('href_link.attrs: ', href_link.attrs) # <a>태그 내부의 모든 속성 출력\n",
    "print('class 속성값: ', href_link['class']) # class 속성의 value 출력\n",
    "\n",
    "print('values():', href_link.attrs.values()) # 모든 속성들의 값 출력\n",
    "\n",
    "values = list(href_link.attrs.values()) # dictionary 값들을 리스트로 변경\n",
    "print(f'values[0]: {values[0]}, values[1]: {values[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "href_value:  <a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "www.google.com\n",
      "google\n"
     ]
    }
   ],
   "source": [
    "href_value = soup.find(attrs={'href' : 'www.google.com'})\n",
    "href_value = soup.find('a', attrs={'href': 'www.google.com'})\n",
    "\n",
    "print('href_value: ', href_value)\n",
    "print(href_value['href'])\n",
    "print(href_value.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "span tag: <span class=\"red\">BeautifulSoup Library Examples!</span>\n",
      "attrs: {'class': ['red']}\n",
      "value: ['red']\n",
      "text: BeautifulSoup Library Examples!\n"
     ]
    }
   ],
   "source": [
    "span_tag = soup.find('span')\n",
    "\n",
    "print('span tag:', span_tag)\n",
    "print('attrs:', span_tag.attrs)\n",
    "print('value:', span_tag.attrs['class'])\n",
    "print('text:', span_tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div_tags length:  3\n",
      "-----------------------------------------------\n",
      "<div id=\"link\">\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "</div>\n",
      "-----------------------------------------------\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "-----------------------------------------------\n",
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# 모든 div 태그를 검색 (리스트 형태로 변환)\n",
    "div_tags = soup.find_all('div')\n",
    "print('div_tags length: ', len(div_tags))\n",
    "\n",
    "for div in div_tags:\n",
    "    print('-----------------------------------------------')\n",
    "    print(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "url: www.google.com, text: google\n",
      "\n",
      "<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
      "url: www.naver.com, text: naver\n",
      "\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "url: /pages/page1.html, text: Page1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links = soup.find_all('a')\n",
    "\n",
    "for alink in links:\n",
    "    print(alink)\n",
    "    print(f\"url: {alink['href']}, text: {alink.string}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"external_link\" href=\"www.google.com\">google</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n"
     ]
    }
   ],
   "source": [
    "link_tags = soup.find_all('a', {'class':['external_link', 'internal_link']})\n",
    "print(link_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<p id=\"third\">class1's third paragraph</p>\n"
     ]
    }
   ],
   "source": [
    "p_tags = soup.find_all('p', {'id':['first', 'third']})\n",
    "for p in p_tags:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup 기초: select_one() 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "<title>BeautifulSoup 활용</title>\n",
      "</head>\n",
      "head.text: BeautifulSoup 활용\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_example, 'html.parser')\n",
    "head = soup.select_one('head')\n",
    "print(head)\n",
    "print('head.text:', head.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"heading\">Heading 1</h1>\n"
     ]
    }
   ],
   "source": [
    "h1 = soup.select_one('h1') # 첫 번째 <h1>태그 선택\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"footer\">Footer</h1>\n"
     ]
    }
   ],
   "source": [
    "# <h1>태그의 id가 \"footer\" 인 항목 추출\n",
    "footer = soup.select_one('h1#footer')\n",
    "# soup.find('h1', {'id': 'footer'})랑 같음\n",
    "print(footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n"
     ]
    }
   ],
   "source": [
    "class_link = soup.select_one('a.internal_link')\n",
    "# soup.find('a', {'class': 'internal_link'})랑 같음\n",
    "print(class_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page1\n",
      "/pages/page1.html\n"
     ]
    }
   ],
   "source": [
    "print(class_link.string)\n",
    "print(class_link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n"
     ]
    }
   ],
   "source": [
    "# 계층적 접근\n",
    "link1 = soup.select_one('div#link > a.external_link')\n",
    "print(link1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n"
     ]
    }
   ],
   "source": [
    "link_find = soup.find('div', {'id': 'link'})\n",
    "external_link = link_find.find('a', {'class': 'external_link'})\n",
    "print(external_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"second\">class1's second paragraph</p>\n",
      "class1's second paragraph\n"
     ]
    }
   ],
   "source": [
    "link2 = soup.select_one('div#class1 p#second')\n",
    "print(link2)\n",
    "print(link2.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pages/page1.html\n",
      "Page1\n"
     ]
    }
   ],
   "source": [
    "internal_link = soup.select_one('div#link a.internal_link')\n",
    "print(internal_link['href'])\n",
    "print(internal_link.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1_all:  [<h1 id=\"heading\">Heading 1</h1>, <h1 id=\"footer\">Footer</h1>]\n"
     ]
    }
   ],
   "source": [
    "h1_all = soup.select('h1')\n",
    "print('h1_all: ', h1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.google.com\n",
      "www.naver.com\n",
      "/pages/page1.html\n"
     ]
    }
   ],
   "source": [
    "# html문서의 모든 <a> 태그의 href 값 추출\n",
    "url_links = soup.select('a')\n",
    "for link in url_links:\n",
    "    print(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n",
      "www.naver.com\n"
     ]
    }
   ],
   "source": [
    "div_urls = soup.select('div#class1 > a')\n",
    "\n",
    "print(div_urls)\n",
    "print(div_urls[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n"
     ]
    }
   ],
   "source": [
    "div_urls2 = soup.select('div#class1 a')\n",
    "\n",
    "print(div_urls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 id=\"heading\">Heading 1</h1>, <h1 id=\"footer\">Footer</h1>]\n"
     ]
    }
   ],
   "source": [
    "# <h1 id=\"heading\">과 <h1 id=\"footer\"> 항목 가져오기\n",
    "h1 = soup.select('#heading, #footer')\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"external_link\" href=\"www.google.com\">google</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n"
     ]
    }
   ],
   "source": [
    "url_links = soup.select('a.external_link, a.internal_link')\n",
    "print(url_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'창문형 에어컨 싸게 팝니다': '50,000원',\n",
       " '제이린드버그골프백': '30,000원',\n",
       " '트립트랩 뉴본세트': '130,000원',\n",
       " '전기자전거': '200,000원',\n",
       " '해바라기버너 및 가스통': '30,000원',\n",
       " '두산베어스 망곰 유니폼 어센틱 100 김택연 정가판매': '135,000원',\n",
       " 'i5 13400f RTX4060 32기가 게이밍 컴퓨터 급처합니다': '500,000원',\n",
       " '이민': '10원',\n",
       " '스카티카메론 퍼터': '30,000원',\n",
       " '복숭아 파지팔아요^^': '10,000원',\n",
       " '실내자전거 오버더바이크': '50,000원',\n",
       " '가방 내놓어요': '105만원',\n",
       " '케리어 이동식에어컨 팔아요': '50,000원',\n",
       " '밀양푸른계곡펜션 카바나양도 8월10일 토요일': '70,000원',\n",
       " '안쓰는 지갑 처리합니다': '999원',\n",
       " '삼성 제습기': '30,000원',\n",
       " '구찌 클러치백 팝니다': '60,000원',\n",
       " '켄싱턴 티켓 3장 팝니다.': '11,000원',\n",
       " '파세코/ 창문형 에어컨': '50,000원',\n",
       " '음료수': '나눔🧡',\n",
       " '맛있는 복숭아 판매합니다': '1원',\n",
       " '사자 이빨': '2억 9,990만원',\n",
       " '(새 상품) 항아리 벌꿀 판매': '14,000원',\n",
       " '삼성 창문형에어컨': '50,000원',\n",
       " '애플워치 se2 44m': '70,000원',\n",
       " '서브마리너 듀얼 톤': '250,000원',\n",
       " '아이폰 14프로 파손폰': '1,000원',\n",
       " '베트남 동 팝니다 600만동': '1원',\n",
       " '그레이트북스 놀라운 자연 74권 + 사진 속 부록들': '180,000원',\n",
       " '냉풍기 필요하신분!!': '10,000원',\n",
       " '크리스피 도넛 (9입)  싸게 팔아요': '4,000원',\n",
       " '갤럭시노트9': '30,000원',\n",
       " '위닉스 제습기': '30,000원',\n",
       " 'LG이동식(창문틀로 더운공기 나가는 방식) 에어컨': '100,000원',\n",
       " '이동식 트롤리 선반': '3,000원',\n",
       " '릴선. 엄청길어요.': '12,000원',\n",
       " '제트니수동카메라': '10,000원',\n",
       " '제습기': '30,000원',\n",
       " '골프채 일괄로 팝니다': '60,000원',\n",
       " '팔공산 펜션양도합니다': '250,000원',\n",
       " '중흥골드스파 워터락': '140,000원',\n",
       " '2in1 엘지 에어컨 입니다( lg 휘센)': '100,000원',\n",
       " '쌀 20kg팝니다': '10,000원',\n",
       " 'Lg 65인치': '200,000원',\n",
       " '주문 마감 했습니다~~~~~~~샤인머스켓 2키로 한상자 5송이4송이': '9억 9,999만 9,999원',\n",
       " '바오바오백-루센트베이지(정품0)': '60,000원',\n",
       " '설탕1kg.소금500g.다시다.간장500ml.후추.미역': '10,000원',\n",
       " '사무실에서 모니터 대량 샀는데 남아서 판매해요': '10,000원',\n",
       " '엔진11 크릿디 급처(가격진짜임)': '250,000원',\n",
       " '필요하신분': '10,000원',\n",
       " '실내 자전거 (전현무 자전거) 오버더바이크 증고': '150,000원',\n",
       " '우영미 반팔 판매합니다': '50,000원',\n",
       " '하츠가스레인지  팝니다': '10,000원',\n",
       " 'LG 미니워시 세탁기, 건조기': '50,000원',\n",
       " '캐리어 창문에어컨': '80,000원',\n",
       " '금 18k 싸게 드려요1gr 10': '500,000원',\n",
       " '이사로 인해서 가전가구 처분합니다!!': '20,000원',\n",
       " '선풍기 판매': '12,000원',\n",
       " 'lg 코드제로 구형 17년도 구매': '40,000원',\n",
       " '오징어 드실분': '1,000원',\n",
       " '야자매트 10미터 39,500원 처분합니다': '39,500원',\n",
       " 'LG냉장고 1등급 254L': '100,000원',\n",
       " '비앙스 회전책장 아이보리': '40,000원',\n",
       " '최강야구 직관 1루 테이블석 양도해요~': '12,345원',\n",
       " '전기자전거 모토벨로 PAS + 스로틀': '250,000원',\n",
       " '냉동고': '50,000원',\n",
       " '전화기가져가실분': '1,000원',\n",
       " '다이슨 선풍기': '100,000원',\n",
       " '65형 커버드t v. 판매합니다': '50,000원',\n",
       " '트립트랩 뉴본 (박스있음)': '90,000원',\n",
       " '1년 쓴 냉장고 급처분 합니다': '30,000원',\n",
       " '메종키츠네 니트 새상품': '32,000원',\n",
       " '모듬해물판매해요': '3,000원',\n",
       " '베란다철제테이블': '10,000원',\n",
       " '트립트랩 뉴본': '80,000원',\n",
       " '트립트랩 하이체어 판매합니다.': '300,000원',\n",
       " '추피 아기책': '20,000원',\n",
       " '아이폰 13미니': '105,000원',\n",
       " '삼성 43인치 스마트 TV': '50,000원',\n",
       " '파세코 3세대 창문형 에어컨': '150,000원',\n",
       " '구찌 클러치백': '20,000원',\n",
       " '중흥골드스파 워터락 이용권': '30,000원',\n",
       " '펜트리': '10,000원',\n",
       " '오늘(7일)299.000원 풀빌라(26평) ㅡ99,000원에 양도': '99,000원',\n",
       " '베베드피노 모자': '32,000원',\n",
       " '벽시계': '1,000원',\n",
       " '눈썹 하실 분 (8월7일)': '50,000원',\n",
       " '주말농장': '40원',\n",
       " '냄비/프라이팬': '5,000원',\n",
       " '전동 자전거 팔아여': '160,000원',\n",
       " '이케아 철제수납장': '10,000원',\n",
       " 'LG 냉장고 사용기간 2년, 제작년도 22년 5월': '100,000원',\n",
       " '아이폰13mini': '250,000원',\n",
       " '냉장고 10만원에 판매 합니다.': '100,000원',\n",
       " '로드자전거 판매': '40,000원',\n",
       " '싸인 만들어드려요': '1,000원'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_list = []\n",
    "product_list = []\n",
    "\n",
    "for i in bs.find_all('div', {'class': 'card-price'}):\n",
    "    price_list.append(i.string.strip())\n",
    "\n",
    "for i in bs.find_all('h2'):\n",
    "    product_list.append(i.string.strip())\n",
    "\n",
    "dict(zip(product_list, price_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
