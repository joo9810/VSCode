AIC(lasso.model) # -45.53
BIC(lasso.model) # -31.79
ols_mallows_cp(lasso.model, full.model) # 9.07 (5에 가까울수록 좋음) <= 차이 4.07
# adjr2가 가장 좋은 모델: bw
# RMSE가 가장 좋은 모델: bw
# AIC가 가장 좋은 모델: bw
# BIC가 가장 좋은 모델: fw 또는 sw
# Cp가 가장 좋은 모델: fw 또는 sw
# 따라서 bw를 최종모델로 선정
hist(df$website)
# 정규성을 만족하는지 확인
hist(df$website)
library(car)
summary(powerTransform(df$website))
# 2001년 1월부터 2002년 8월까지의 자료
# 고객에게 전달된 웹사이트의 수에 가장 큰 영향을 미치는 변수가 어떤 것인지 관심
setwd('I:/수업/2022학년도/2학기/통계전산실습')
data.set <- read.table('Web_Developer.txt')
str(data.set) # 73행 8열
# 결측치 확인
colSums(is.na(data.set)) # 결측치 0개
colnames(data.set) <- c('id', 'website', 'balance', 'team', 'exper', 'change', 'year', 'semester')
df <- data.set
# H0: 데이터가 정규분포를 따른다, H1: 데이터가 정규분포를 따르지 않는다
shapiro.test(data.set$website) # 정규분포를 따르지 않음
library(nortest)
ad.test(data.set$website) # 정규분포를 따르지 않음
shapiro.test(data.set$exper) # 정규분포를 따르지 않음
ad.test(data.set$exper) # 정규분포를 따르지 않음
# 수치형 변수(V2, V3, V5)의 상자그림
boxplot(data.set$website ~ data.set$team, xlab = '팀',
ylab = '전달된 웹사이트', main = '팀별 전달된 웹사이트의 상자그림') # V2, V3에서 이상치 존재
# 이상치가 포함된 행 확인
Q3_website <- as.numeric(summary(data.set$website)[5]) ; Q3_website # V2의 3사분위 수
Q1_balance <- as.numeric(summary(data.set$balance)[2]) ; Q1_balance # V3의 1사분위 수
upper_website <- Q3_website + 1.5*IQR(data.set$website) ; upper_website # V2의 위쪽 바깥 울타리
lower_balance <- Q1_balance - 1.5*IQR(data.set$balance) ; lower_balance # V3의 아래쪽 바깥 울타리
outV2_index <- which(data.set$website > upper_website) ; outV2_index # 50번 인덱스
outV3_index <- which(data.set$balance < lower_balance) ; outV3_index # 65번 인덱스
data.set[50,] # V2값이 30으로 위쪽 바깥 울타리인 28보다 큼 (이상치)
data.set[65,] # V3값이 3으로 아래쪽 바깥 울타리인 6.5보다 작음 (이상치)
df <- data.set[-c(50,64),]
df <- data.set
# 문제1: 절차 변경을 했을 때와 안했을 때의 전달된 웹사이트 수에 차이가 있는지
# 개발 절차를 변경하고 나서 고객에게 전달된 웹사이트의 수가 더 많을 것으로 추측
after <- df$website[df$change == 1] # 절차를 변경한 그룹
before <- df$website[df$change == 0] # 절차를 변경하지 않은 그룹
wilcox.test(after, before, alternative = 'greater')
t.test(after, before, alternative = 'greater')
# 문제2: 2001년과 2002년의 전달된 웹사이트 수에 차이가 있는지
# 2002년 2분기와 3분기에 개발 절차가 변경되었기 때문에 2001년보다 2002년도에
# 고객에게 전달된 웹사이트의 수가 더 많을 것으로 추측
y_2001 <- df$website[df$year == 2001] # 2001년인 그룹
y_2002 <- df$website[df$year == 2002] # 2002년인 그룹
wilcox.test(y_2001, y_2002, alternative = 'less')
t.test(y_2001, y_2002, alternative = 'less')
# 문제3: 분기에 따라 전달된 웹사이트 수에 차이가 있는지
# H0: median1 = median2 = median3 = median4, H1: 중앙값이 다른게 적어도 하나 이상 있다
result <- kruskal.test(website ~ factor(semester), data = df) ; result
result <- aov(website ~ factor(semester), data = df) ; result
# 사후분석
library(dunn.test)
dunn.test(df$website, factor(df$semester), method = 'bonferroni')
Q1_2001 <- df[df$semester == 1 & df$year == 2001,9] # 2001년 1분기 총 주문
Q2_2001 <- df[df$semester == 2 & df$year == 2001,9] # 2001년 2분기 총 주문
Q3_2001 <- df[df$semester == 3 & df$year == 2001,9] # 2001년 3분기 총 주문
Q4_2001 <- df[df$semester == 4 & df$year == 2001,9] # 2001년 4분기 총 주문
Q1_2002 <- df[df$semester == 1 & df$year == 2002,9] # 2002년 1분기 총 주문
Q2_2002 <- df[df$semester == 2 & df$year == 2002,9] # 2002년 2분기 총 주문
Q3_2002 <- df[df$semester == 3 & df$year == 2002,9] # 2002년 3분기 총 주문
tq1 <- sum(Q1_2001) # 2001년 1분기에 총 136개의 주문을 고객이 함
tq2 <- sum(Q2_2001) # 2001년 1분기에 총 210개의 주문을 고객이 함
tq3 <- sum(Q3_2001) # 2001년 1분기에 총 293개의 주문을 고객이 함
tq4 <- sum(Q4_2001) # 2001년 1분기에 총 315개의 주문을 고객이 함
plot(c(tq1,tq2,tq3,tq4))
# 문제4: 팀 번호에 따라 전달된 웹사이트 수에 차이가 있는지
# H0: median1 = median2 = ... = median13, H1: 중앙값이 다른게 적어도 하나 이상 있다
result2 <- kruskal.test(website ~ factor(team), data = df) ; result2
plot(df$exper, df$website, xlab = '팀 경험기간',
ylab = '전달된 웹사이트', main = '팀 경험기간과 전달된 웹사이트의 산점도')
cor.test(df$website, df$exper, method = 'spearman')
# min-max 스케일링
df$website <- (df$website - min(df$website)) / (max(df$website) - min(df$website))
# 2001년 1월부터 2002년 8월까지의 자료
# 고객에게 전달된 웹사이트의 수에 가장 큰 영향을 미치는 변수가 어떤 것인지 관심
setwd('I:/수업/2022학년도/2학기/통계전산실습')
data.set <- read.table('Web_Developer.txt')
str(data.set) # 73행 8열
# 결측치 확인
colSums(is.na(data.set)) # 결측치 0개
colnames(data.set) <- c('id', 'website', 'balance', 'team', 'exper', 'change', 'year', 'semester')
df <- data.set
# 범주형 변수 지시변수화
df$change1 <- ifelse(df$change == 1, 1, 0)
df$year2002 <- ifelse(df$year == 2002, 1, 0)
df$semester2 <- ifelse(df$semester == 2, 1, 0)
df$semester3 <- ifelse(df$semester == 3, 1, 0)
df$semester4 <- ifelse(df$semester == 4, 1, 0)
str(df)
# 정규성을 만족하는지 확인
hist(df$website) # 왼쪽으로 치우친 분포
library(car)
summary(powerTransform(df$website))
hist(log(df$website))
shapiro.test(log(df$website))
shapiro.test(df$website)
df$website
log(df$website)
shapiro.test(log(df$website + 1))
hist(log(df$website + 1))
hist(log(df$website + 0.1))
hist(log(df$website + 1))
shapiro.test(log(df$website + 1))
shapiro.test(df$website)
install.packages('geoR')
library(geoR)
boxcoxfit(df$website)
# 정규성을 만족하는지 확인
hist(df$website) # 왼쪽으로 치우친 분포
hist(sqrt(df$website))
shapiro.test(sqrt(df$website))
hist(df$balance)
shapiro.test(df$website)
hist(df$balance)
shapiro.test(df$balance)
hist(df$exper)
exper
df$exper
df$website <- sqrt(df$website)
df$exper
summary(powerTransform(df$exper))
powerTransform(df$exper)$lambda
lam <- powerTransform(df$exper)$lambda # 람다값 0.5581837
df$exper <- (df$exper^lam - 1) / lam
hist(df$exper)
shapiro.test(df$exper)
# 2001년 1월부터 2002년 8월까지의 자료
# 고객에게 전달된 웹사이트의 수에 가장 큰 영향을 미치는 변수가 어떤 것인지 관심
setwd('I:/수업/2022학년도/2학기/통계전산실습')
data.set <- read.table('Web_Developer.txt')
str(data.set) # 73행 8열
# 결측치 확인
colSums(is.na(data.set)) # 결측치 0개
colnames(data.set) <- c('id', 'website', 'balance', 'team', 'exper', 'change', 'year', 'semester')
df <- data.set
# 정규성을 만족하는지 확인
hist(df$website) # 왼쪽으로 치우친 분포
shapiro.test(df$website) # 정규분포를 따르지 않음
shapiro.test(df$website) # 정규분포를 따르지 않음 (p-value = 3.467e-05)
# 값에 0이 포함되어 있어 box-cox를 진행할 수 없음
# 왼쪽으로 치우쳐져 있으므로 log변환 또는 제곱근 변환을 고려할 수 있으며
# log변환은 값에 0이 있기 때문에 불가능하므로 제곱근 변환 시도
hist(sqrt(df$website)) # 제곱근 변환
shapiro.test(sqrt(df$website)) # 정규분포를 따름
shapiro.test(sqrt(df$website)) # 정규분포를 따름 (p-value = 0.1834)
df$website <- sqrt(df$website)
hist(df$balance)
shapiro.test(df$balance) # 정규분포를 따름
hist(df$exper)
shapiro.test(df$ex)
shapiro.test(df$exper)
summary(powerTransform(df$exper))
summary(powerTransform(df$exper))
lam <- powerTransform(df$exper)$lambda # 람다값 0.5581837
df$exper <- (df$exper^lam - 1) / lam
hist(df$exper)
shapiro.test(df$exper)
# 1. min-max 스케일링
df$website <- (df$website - min(df$website)) / (max(df$website) - min(df$website))
df$balance <- (df$balance - min(df$balance)) / (max(df$balance) - min(df$balance))
df$exper <- (df$exper - min(df$exper)) / (max(df$exper) - min(df$exper))
hist(df$exper)
shapiro.test(df$exper) # 비록 유의수준 0.05 하에서는 정규성을 띄지 않지만
# 범주형 변수 지시변수화
df$change1 <- ifelse(df$change == 1, 1, 0)
df$year2002 <- ifelse(df$year == 2002, 1, 0)
df$semester2 <- ifelse(df$semester == 2, 1, 0)
df$semester3 <- ifelse(df$semester == 3, 1, 0)
df$semester4 <- ifelse(df$semester == 4, 1, 0)
str(df)
# 풀 모델
full.model <- lm(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:change1 +
balance:year2002 + balance:semester2 + balance:semester3 +
balance:semester4 + exper:change1 + exper:year2002 +
exper:semester2 + exper:semester3 + exper:semester4, data = df)
summary(full.model) # adjr2 = 0.5164, RMSE = 0.6954
forw <- lm(website ~ 1, data = df) # 상수항만 활용
back <- full.model # 모든 변수 활용
# 전진선택법
# 절편만 있는 상수모형으로부터 시작해 중요하다고 생각되는
# 설명변수부터 차례로 모형에 추가
# 장점: 이해하기 쉽고 변수의 개수가 많은 경우에도 사용 가능
# 단점: 변수값의 작은 변동에도 결과가 크게 달라져 안정성이 부족함
fw <- step(forw, direction = 'forward', scope = list(lower = forw, upper = back))
# website ~ change1 + semester3 + balance + semester3:balance
summary(fw)
# 후진소거법
# 모든 독립변수를 포함한 모형에서 출발해 가장 적은 영향을 주는 변수부터
# 하나씩 제거하면서 더 이상 제거할 변수가 없을 때까지 진행
# 장점: 전체 변수들의 정보를 이용할 수 있음
# 단점: 변수의 개수가 많으면 사용하기 어려움
bw <- step(back, direction = 'backward')
# website ~ balance + exper + change1 + semester2 + semester3 +
# semester4 + balance:exper + balance:semester2 + balance:semester3 +
# balance:semester4
summary(bw)
# 단계선택법
# 전진선택법에 의해 변수를 추가하면서 새롭게 추가된 변수에 기반하여,
# 기존 변수의 중요도가 약화되면 해당 변수를 제거하며,
# 단계별로 추가 또는 제거되는 변수의 여부를 검토하여
# 더 이상 변경사항이 없을 때까지 진행
sw <- step(forw, direction = 'both', scope = list(upper = back))
# website ~ change1 + semester3 + year2002
summary(sw)
# 라쏘회귀
set.seed(764345)
library(glmnet)
x <- model.matrix(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:change1 +
balance:year2002 + balance:semester2 + balance:semester3 +
balance:semester4 + exper:change1 + exper:year2002 +
exper:semester2 + exper:semester3 + exper:semester4, data = df)[,-1]
y <- df$website
lasso.result <- cv.glmnet(x, y, alpha = 1)
plot(lasso.result)
bestlam.lasso <- lasso.result$lambda.min
predict(lasso.result, s = bestlam.lasso, newx = x, type = 'coefficients')
# website ~ change1 + year2002 + semester3 + semester4 + balance:exper +
# balance:year2002 + balance:semester2 + exper:semester3
lasso.model <- lm(website ~ change1 + year2002 + semester3 + semester4 + balance:exper +
balance:year2002 + balance:semester2 + exper:semester3, data = df)
summary(lasso.model)
summary(fw) # adjr2 = 0.4936, RMSE = 0.168
# website ~ change1 + year2002 + semester3 + semester4 + balance:exper +
# balance:year2002 + balance:semester2 + exper:semester3
lasso.model <- lm(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:year2002 +
balance:semester2 + exper:semester3, data = df)
summary(lasso.model)
# 라쏘회귀
set.seed(7640)
library(glmnet)
x <- model.matrix(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:change1 +
balance:year2002 + balance:semester2 + balance:semester3 +
balance:semester4 + exper:change1 + exper:year2002 +
exper:semester2 + exper:semester3 + exper:semester4, data = df)[,-1]
y <- df$website
lasso.result <- cv.glmnet(x, y, alpha = 1)
plot(lasso.result)
bestlam.lasso <- lasso.result$lambda.min
predict(lasso.result, s = bestlam.lasso, newx = x, type = 'coefficients')
# 모든 가능한 회귀
library(leaps)
al <- regsubsets(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:change1 +
balance:year2002 + balance:semester2 + balance:semester3 +
balance:semester4 + exper:change1 + exper:year2002 +
exper:semester2 + exper:semester3 + exper:semester4, data = df)
summary(al)
al.result <- summary(al) ; al.result
al1 <- lm(website ~ change1, data = df)
summary(al1)
al2 <- lm(website ~ change1 + semester3)
al2 <- lm(website ~ change1 + semester3, data = df)
summary(al2)
summary(al1)
al3 <- lm(website ~ change1 + semester3 + balance:semester3)
al3 <- lm(website ~ change1 + semester3 + balance:semester3, data = df)
summary(al3)
al4 <- lm(website ~ balance + change1 + semester3 + balance:semester3, data = df)
summary(al4)
al3 <- lm(website ~ balance + change1 + semester3 + balance:semester3, data = df)
summary(al3)
al4 <- lm(website ~ balance + exper + change1 + semester3 + semester4 +
balance:exper + balance:semester3 + balance:semester4, data = df)
summary(al4)
# 전진선택법
# 절편만 있는 상수모형으로부터 시작해 중요하다고 생각되는
# 설명변수부터 차례로 모형에 추가
# 장점: 이해하기 쉽고 변수의 개수가 많은 경우에도 사용 가능
# 단점: 변수값의 작은 변동에도 결과가 크게 달라져 안정성이 부족함
fw <- step(forw, direction = 'forward', scope = list(lower = forw, upper = back))
# website ~ change1 + semester3 + balance + semester3:balance
summary(fw)
# 후진소거법
# 모든 독립변수를 포함한 모형에서 출발해 가장 적은 영향을 주는 변수부터
# 하나씩 제거하면서 더 이상 제거할 변수가 없을 때까지 진행
# 장점: 전체 변수들의 정보를 이용할 수 있음
# 단점: 변수의 개수가 많으면 사용하기 어려움
bw <- step(back, direction = 'backward')
# website ~ balance + exper + change1 + semester2 + semester3 +
# semester4 + balance:exper + balance:semester2 + balance:semester3 +
# balance:semester4
summary(bw)
summary(al4)
# website ~ balance + exper + change1 + semester2 + semester3 +
# semester4 + balance:exper + balance:semester2 + balance:semester3 +
# balance:semester4
summary(bw)
# 단계선택법
# 전진선택법에 의해 변수를 추가하면서 새롭게 추가된 변수에 기반하여,
# 기존 변수의 중요도가 약화되면 해당 변수를 제거하며,
# 단계별로 추가 또는 제거되는 변수의 여부를 검토하여
# 더 이상 변경사항이 없을 때까지 진행
sw <- step(forw, direction = 'both', scope = list(upper = back))
# website ~ change1 + semester3 + balance + semester3:balance
summary(sw)
# 라쏘회귀
set.seed(7640)
library(glmnet)
x <- model.matrix(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:change1 +
balance:year2002 + balance:semester2 + balance:semester3 +
balance:semester4 + exper:change1 + exper:year2002 +
exper:semester2 + exper:semester3 + exper:semester4, data = df)[,-1]
y <- df$website
lasso.result <- cv.glmnet(x, y, alpha = 1)
plot(lasso.result)
bestlam.lasso <- lasso.result$lambda.min
predict(lasso.result, s = bestlam.lasso, newx = x, type = 'coefficients')
lasso.model <- lm(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:year2002 +
balance:semester2 + exper:semester3, data = df)
summary(lasso.model)
predict(lasso.result, s = bestlam.lasso, newx = x, type = 'coefficients')
# 라쏘회귀
set.seed(9810)
library(glmnet)
x <- model.matrix(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:change1 +
balance:year2002 + balance:semester2 + balance:semester3 +
balance:semester4 + exper:change1 + exper:year2002 +
exper:semester2 + exper:semester3 + exper:semester4, data = df)[,-1]
y <- df$website
lasso.result <- cv.glmnet(x, y, alpha = 1)
plot(lasso.result)
bestlam.lasso <- lasso.result$lambda.min
predict(lasso.result, s = bestlam.lasso, newx = x, type = 'coefficients')
# 라쏘회귀
set.seed(9811)
library(glmnet)
x <- model.matrix(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:change1 +
balance:year2002 + balance:semester2 + balance:semester3 +
balance:semester4 + exper:change1 + exper:year2002 +
exper:semester2 + exper:semester3 + exper:semester4, data = df)[,-1]
y <- df$website
lasso.result <- cv.glmnet(x, y, alpha = 1)
plot(lasso.result)
bestlam.lasso <- lasso.result$lambda.min
predict(lasso.result, s = bestlam.lasso, newx = x, type = 'coefficients')
# 라쏘회귀
set.seed(1234)
library(glmnet)
x <- model.matrix(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:change1 +
balance:year2002 + balance:semester2 + balance:semester3 +
balance:semester4 + exper:change1 + exper:year2002 +
exper:semester2 + exper:semester3 + exper:semester4, data = df)[,-1]
y <- df$website
lasso.result <- cv.glmnet(x, y, alpha = 1)
plot(lasso.result)
bestlam.lasso <- lasso.result$lambda.min
predict(lasso.result, s = bestlam.lasso, newx = x, type = 'coefficients')
# 라쏘회귀
set.seed(3587)
library(glmnet)
x <- model.matrix(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:change1 +
balance:year2002 + balance:semester2 + balance:semester3 +
balance:semester4 + exper:change1 + exper:year2002 +
exper:semester2 + exper:semester3 + exper:semester4, data = df)[,-1]
y <- df$website
lasso.result <- cv.glmnet(x, y, alpha = 1)
plot(lasso.result)
bestlam.lasso <- lasso.result$lambda.min
predict(lasso.result, s = bestlam.lasso, newx = x, type = 'coefficients')
lasso.model <- lm(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:year2002 +
balance:semester2 + exper:semester3, data = df)
summary(fw) # adjr2 = 0.4936, RMSE = 0.168
AIC(fw) # -47.36
BIC(fw) # -35.91
ols_mallows_cp(fw, full.model) # 7.24 (4에 가까울수록 좋음) <= 차이 3.24
# AIC 는 예측능력이 높은 모형을 좋은 모형으로 선정
# BIC 는 자료 설명력이 높은 모형을 좋은 모형으로 선정
# BIC 는 AIC 에 비하여 단순한 모형을 좋은 모형으로 선정함
library(olsrr)
ols_mallows_cp(fw, full.model) # 7.24 (4에 가까울수록 좋음) <= 차이 3.24
summary(fw) # adjr2 = 0.5287, RMSE = 0.1509
summary(bw) # adjr2 = 0.5723, RMSE = 0.1544
AIC(bw) # -55.19
BIC(bw) # -32.28
ols_mallows_cp(bw, full.model) # 1.59 (6에 가까울수록 좋음) <= 차이 4.41
6-4.538355
summary(bw) # adjr2 = 0.5718, RMSE = 0.1438
AIC(bw) # -63.86723
BIC(bw) # -36.38172
ols_mallows_cp(bw, full.model) # 4.538355 (6에 가까울수록 좋음) <= 차이 1.461645
summary(bw) # adjr2 = 0.5718, RMSE = 0.1438
summary(fw) # adjr2 = 0.5287, RMSE = 0.1509
summary(sw) # adjr2 = 0.4936, RMSE = 0.168
AIC(sw) # -47.36
BIC(sw) # -35.91
ols_mallows_cp(sw, full.model) # 7.24 (4에 가까울수록 좋음) <= 차이 3.24
summary(al1)
summary(al2)
summary(al3)
summary(al4)
AIC(al4)
BIC(al4)
ols_mallows_cp(al4, full.model)
summary(al3) # # adjr2 = 0.5669, RMSE = 0.1447
AIC(al3) # -64.71299
BIC(al3) # -41.80839
ols_mallows_cp(al3, full.model)
allp <- regsubsets(website ~ balance + exper + change1 + year2002 + semester2 +
semester3 + semester4 + balance:exper + balance:change1 +
balance:year2002 + balance:semester2 + balance:semester3 +
balance:semester4 + exper:change1 + exper:year2002 +
exper:semester2 + exper:semester3 + exper:semester4, data = df)
al.result <- summary(alp) ; al.result
al.result <- summary(allp) ; al.result
# website ~ balance + exper + change1 + semester3 + semester4 +
# balance:exper + balance:semester3 + balance:semester4
al <- lm(website ~ balance + exper + change1 + semester3 + semester4 +
balance:exper + balance:semester3 + balance:semester4, data = df)
summary(al4)
summary(al)
summary(al) # # adjr2 = 0.5669, RMSE = 0.1447
AIC(al) # -64.71299
BIC(al) # -41.80839
ols_mallows_cp(al, full.model)
6-2.990701
vif(al)
vif(fw)
vif(bw)
vif(sw)
vif(full.model)
summary(sw) # adjr2 = 0.4936, RMSE = 0.168
summary(al) # # adjr2 = 0.5669, RMSE = 0.1447
summary(fw) # adjr2 = 0.5287, RMSE = 0.1509
summary(bw) # adjr2 = 0.5718, RMSE = 0.1438
summary(sw) # adjr2 = 0.4936, RMSE = 0.168
AIC(sw) # -62.12077
BIC(sw) # -48.37802
vif(fw)
summary(bw) # adjr2 = 0.5718, RMSE = 0.1438
AIC(bw) # -63.86723
BIC(bw) # -36.38172
ols_mallows_cp(bw, full.model) # 4.538355 (7에 가까울수록 좋음) <= 차이 2.461645
vif(bw)
summary(sw) # adjr2 = 0.4936, RMSE = 0.168
AIC(sw) # -62.12077
BIC(sw) # -48.37802
ols_mallows_cp(sw, full.model) # 4.046173 (4에 가까울수록 좋음) <= 차이 0.046173
vif(sw)
bw1 <- lm(website ~ change1 + semester3 + balance, data = df)
summary(bw1)
vif(bw)
vif(sw)
vif(bw)
summary(sw) # adjr2 = 0.4936, RMSE = 0.168
summary(bw1)
summary(sw) # adjr2 = 0.4936, RMSE = 0.168
summary(fw) # adjr2 = 0.5287, RMSE = 0.1509
AIC(fw) # -62.12077
BIC(fw) # -48.37802
ols_mallows_cp(fw, full.model) # 4.046173 (4에 가까울수록 좋음) <= 차이 0.046173
vif(fw)
summary(bw) # adjr2 = 0.5718, RMSE = 0.1438
bw1 <- lm(website ~ change1 + semester3 + balance, data = df)
summary(bw1)
vif(bw1)
vif(sw)
vif(fw)
vif(bw)
vif(fw)
vif(full.model) # vif값이 매우 큼
vif(full.model, terms = 'marginal') # vif값이 매우 큼
vif(full.model, terms = 'high-order') # vif값이 매우 큼
vif(full.model, type = 'predictor') # vif값이 매우 큼
vif(full.model) # vif값이 매우 큼
vif(full.model, type="high-order") # vif값이 매우 큼
vif(full.model, type="terms") # vif값이 매우 큼
vif(full.model, type="marginal") # vif값이 매우 큼
vif(fw, type = 'marginal') # 비록 아직 vif값이 크지만 이전 결과보다는 많이 감소시킴
summary(fw) # adjr2 = 0.5287, RMSE = 0.1509
AIC(fw) # -62.12077
BIC(fw) # -48.37802
ols_mallows_cp(fw, full.model) # 4.046173 (4에 가까울수록 좋음) <= 차이 0.046173
vif(fw, type = 'marginal') # 비록 아직 vif값이 크지만 이전 결과보다는 많이 감소시킴
vif(fw)
vif(fw, type = 'marginal') # 비록 아직 vif값이 크지만 이전 결과보다는 많이 감소시킴
vif(fw, type = 'high-order')
vif(fw, type = 'high-order')
vif(fw, type = 'marginal') # 비록 아직 vif값이 크지만 이전 결과보다는 많이 감소시킴
vif(fw, type = 'marginal') #
summary(bw) # adjr2 = 0.5718, RMSE = 0.1438
AIC(bw) # -63.86723
BIC(bw) # -36.38172
ols_mallows_cp(bw, full.model) # 4.538355 (7에 가까울수록 좋음) <= 차이 2.461645
vif(bw) # 비록 아직 vif값이 크지만 이전 결과보다는 많이 감소시킴
vif(bw, type = 'marginal') # 비록 아직 vif값이 크지만 이전 결과보다는 많이 감소시킴
summary(sw) # adjr2 = 0.5287, RMSE = 0.1509
AIC(sw) # -62.12077
BIC(sw) # -48.37802
ols_mallows_cp(sw, full.model) # 4.046173 (4에 가까울수록 좋음) <= 차이 0.046173
vif(sw) # 비록 아직 vif값이 크지만 이전 결과보다는 많이 감소시킴
vif(sw, type = 'marginal') # 비록 아직 vif값이 크지만 이전 결과보다는 많이 감소시킴
