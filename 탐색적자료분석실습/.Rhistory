data.set <- data.frame(x = x, y = y)
# 1번 산점도
plot(data.set$x, data.set$y)
# 2번 회귀계수 추정
lm.result <- lm(formula = y ~ x, data = data.set)
lm.result
# 2번 오차항의 표준편차 추정
anova(lm.result)
# 3번 회귀계수 유의성 검정
summary(lm.result)
# 4번
confint(lm.result)
# 5번 x가 10일 때의 y에 대한 95% 예측구간
new.data   <- data.frame( x = 10 )
predict( lm.result , newdata = new.data , level = 0.95 , interval = "prediction" )
# 4번
confint(lm.result)
# 3번 회귀계수 유의성 검정
summary(lm.result)
# 4번
beta0-hat <- 15.432
# 4번
beta0_hat <- 15.432
t <- qt(0.975,8)
# 2번 오차항의 표준편차 추정
anova(lm.result)
str(anova(lm.result))
sigma_hat <- anova(lm.result)$Mean Sq
# 2번 오차항의 표준편차 추정
a <- anova(lm.result)
# 2번 오차항의 표준편차 추정
anova.table <- anova(lm.result)
anova.table$`Mean Sq`[2]
MSE <- anova.table$`Mean Sq`[2]
sqrt(MSE)
# 2번 오차항의 표준편차 추정
anova.table <- anova(lm.result)
MSE <- anova.table$`Mean Sq`[2]
sqrt(MSE)
# 2번 회귀계수 추정
lm.result <- lm(formula = y ~ x, data = data.set)
lm.result
# 2번 오차항의 표준편차 추정
anova.table <- anova(lm.result)
MSE <- anova.table$`Mean Sq`[2]
sqrt(MSE)
anova.table
sqrt(26.3)
sum((x-mean(x))^2)
anova.table
lm.result
(15.432^2)*61.6
sigma_hat <- sqrt(MSE)
Sxx <- sum((x-mean(x))^2)
c(beta0_hat - t*sigma_hat/sqrt(Sxx), beta0_hat + t*sigma_hat/sqrt(Sxx))
t
confint(lm.result)
lm.result
lm.result$coefficients[2]
# 4번
beta0_hat <- lm.result$coefficients[2]
t <- qt(0.975,8)
sigma_hat <- sqrt(MSE)
Sxx <- sum((x-mean(x))^2)
c(beta0_hat - t*sigma_hat/sqrt(Sxx), beta0_hat + t*sigma_hat/sqrt(Sxx))
confint(lm.result)
# 4번
beta0_hat <- lm.result$coefficients[2]
t <- qt(0.975,8)
sigma_hat <- sqrt(MSE)
Sxx <- sum((x-mean(x))^2)
c(beta0_hat - t*sigma_hat/sqrt(Sxx), beta0_hat + t*sigma_hat/sqrt(Sxx))
confint(lm.result)
x <- c(5,2,4,7,1,8,2,5,7,1)
y <- c(78,31,62,110,15,125,25,66,98,12)
data.set <- data.frame(x = x, y = y)
# 1번 산점도
plot(data.set$x, data.set$y)
# 2번 회귀계수 추정
lm.result <- lm(formula = y ~ x, data = data.set)
lm.result
# 2번 오차항의 표준편차 추정
anova.table <- anova(lm.result)
MSE <- anova.table$`Mean Sq`[2]
sqrt(MSE)
# 3번 회귀계수 유의성 검정
summary(lm.result)
# 4번
beta0_hat <- lm.result$coefficients[2]
t <- qt(0.975,8)
sigma_hat <- sqrt(MSE)
Sxx <- sum((x-mean(x))^2)
c(beta0_hat - t*sigma_hat/sqrt(Sxx), beta0_hat + t*sigma_hat/sqrt(Sxx))
confint(lm.result) # confint 함수 이용
# 5번 x가 10일 때의 y에 대한 95% 예측구간
new.data   <- data.frame( x = 10 )
predict( lm.result , newdata = new.data , level = 0.95 , interval = "prediction" )
confint(lm.result) # confint 함수 이용
confint(lm.result) # confint 함수 이용
confint(lm.result,2) # confint 함수 이용
summary(lm.result)
setwd()
setwd("J:/수업/2022학년도/회귀분석실습")
ton <- read.csv("ton.csv",header = T)
setwd("J:/수업/2022학년도/회귀분석실습")
ton <- read.csv("ton.csv",header = T)
setwd("J:/수업/2022학년도/회귀분석실습")
ton <- read.csv("ton.csv",header = T)
setwd("J:/수업/2022학년도/회귀분석실습")
ton <- read.csv("ton.csv",header = T)
plot(x = ton$x, y = ton$y)
lm(formula = y ~ x, data = ton)
abline(lm(formula = y ~ x, data = ton))
lm.result <- lm(formula = y ~ x, data = ton)
abline(lm.result)
data.frame(x = 50)
newdata <- data.frame(x = 50)
predict(lm.result, newdata = newdata, level = 0.95, interval = "confidence")
predict(lm.result, newdata = newdata, level = 0.95, interval = "prediction")
data <- read.csv("Exercise3.1", header = T)
data <- read.csv("Exercise3.1.csv", header = T)
objective <- function(b, x, y){
b0 <- b[1]
b1 <- b[2]
pred <- b0 + b1 * x
sum.of.square <- sum((y-pred)^2)
return(sum.of.square)
}
optim(par = c(1,1), fn = objective, method = "BFGS",
x = data$airTemp, y = data$fuel)
data
lm(formula = fuel ~ airTemp, data = data)
x <- c(5,2,4,7,1,8,2,5,7,1)
y <- c(78,31,62,110,15,125,25,66,98,12)
data <- data.frame(x = x, y = y)
plot(x = data$x, y = data$y)
lm(formula = y ~ x, data = data)
lm.result <- lm(formula = y ~ x, data = data)
anova(lm.result)
summary(lm.result)
sqrt(26.3)
summary(lm.result)
confint(lm.result,2,level = 0.95)
newdata <- data.frame(x = 10)
predict(lm.result,newdata = newdata, level = 0.95, interval = "prediction")
x <- c(20,20,20,40,40,40,60,60,60)
y <- c(86,80,77,78,84,75,33,38,43)
data <- data.frame(x = x, y = y)
data$z <- factor(data$x)
full_model <- lm(formula = y ~ z, data = data)
reduced_model <- lm(formula = y ~ x, data = data)
anova(reduced_model, full_model)
anova(full_model, reduced_model)
x <- c(1,2,3,4,5,6,7,8,9,10)
y <- c(170,106,92,80,69,47,45,30,28,18)
data <- data.frame(x = x, y = y)
lm(formula = y ~ x, data = data)
lm(formula = log(y) ~ x, data = data)
lm(formula = y ~ log(x), data = data)
lm(formula = log(y) ~ log(x), data = data)
lm.result1 <- lm(formula = y ~ x, data = data)
lm.result2 <- lm(formula = log(y) ~ x, data = data)
lm.result3 <- lm(formula = y ~ log(x), data = data)
lm.result4 <- (formula = log(y) ~ log(x), data = data)
lm.result4 <- lm(formula = log(y) ~ log(x), data = data)
summary(lm.result1)
summary(lm.result2)
summary(lm.result3)
summary(lm.result4)
str(summary(lm.result1))
summary(lm.result1)$r.squared
summary(lm.result2)$r.squared
summary(lm.result3)$r.squared
summary(lm.result4)$r.squared
newdata <- data.frame(x = 11)
predict(lm.result2, newdata = newdata, level = 0.95, interval = "prediction")
predict(lm.result3, newdata = newdata, level = 0.95, interval = "prediction")
x <- c(5,2,4,7,1,8,2,5,7,1)
y <- c(78,31,62,110,15,125,25,66,98,12)
predict(lm.result3, newdata = newdata, level = 0.95, interval = "prediction")
pred_result <- predict(lm.result3, newdata = newdata, level = 0.95, interval = "prediction")
pred_result[2]
c(exp(pred_result[2]), exp(pred_result[3])
c(exp(pred_result[2]), exp(pred_result[3])
c(exp(pred_result[2]), exp(pred_result[3]))
predict(lm.result,newdata = newdata, level = 0.95, interval = "prediction")
data <- data.frame(x = x, y = y)
lm.result1 <- lm(formula = y ~ x, data = data)
lm.result2 <- lm(formula = y ~ 0 + x, data = data)
lm.result1
lm.result2
summary(lm.result2)
summary(lm.result1)
plot(lm.result2)
x1 <- c(4,4,6,6,8,8)
x2 <- c(2,6,2,6,2,6)
y <- c(64,81,72,91,83,96)
data <- data.frame(x1 = x1, x2 = x2, y = y)
data
plot(x1,y)
lm(y~x1)
abline(lm(y~x1))
plot(x2,y)
summary(lm(formula = y ~ x1, data = data))
summary(lm(formula = y ~ x2, data = data))
summary(lm.result)
lm.result <- lm(formula = y ~ x1 + x2, data = data)
summary(lm.result)
lm.result1 <- lm(formula = y ~ x1, data = data)
lm.result2 <- lm(formula = y ~ x2, data = data)
lm.result3 <- lm(formula = y ~ x1 + x2, data = data)
lm.result4 <- lm(formula = x1 ~ x2, data = data)
lm.result5 <- lm(formula = x2 ~ x1, data = data)
data1 <- data.frame(z1 = residuals(lm.result1),
z2 = residuals((lm.result4)))
lm.result6 <- lm(formula = z1 ~ z2, data = data1)
lm.result3$coefficients
lm.result6$coefficients
data1 <- data.frame(z1 = residuals(lm.result2),
z2 = residuals((lm.result4)))
lm.result6 <- lm(formula = z1 ~ z2, data = data1)
lm.result3$coefficients
lm.result6$coefficients
data2 <- data.frame(z1 = residuals(lm.result1),
z2 = residuals(lm.result5))
lm.result7 <- lm(formula = z1 ~ z2, data = data2)
lm.result7$coefficients
lm.result$coefficients
lm.result1 <- lm(formula = y ~ x1, data = data)
lm.result1
lm.result2 <- lm(formula = y ~ x2, data = data)
lm.result2
lm.result3 <- lm(formula = y ~ x1 + x2, data = data)
lm.result3
lm.result2 <- lm(formula = y ~ x2, data = data)
lm.result4 <- lm(formula = x1 ~ x2, data = data)
data1 <- data.frame(z1 = residuals(lm.result2),
z2 = residuals((lm.result4)))
lm.result6 <- lm(formula = z1 ~ z2, data = data1)
data1 <- data.frame(z1 = residuals(lm.result2), z2 = residuals((lm.result4)))
lm.result2 <- lm(formula = y ~ x2, data = data)
lm.result4 <- lm(formula = x1 ~ x2, data = data)
data1 <- data.frame(z1 = residuals(lm.result2), z2 = residuals((lm.result4)))
lm.result6 <- lm(formula = z1 ~ z2, data = data1)
lm.result3$coefficients
lm.result6$coefficients
lm.result6 <- lm(formula = z2 ~ z1, data = data1)
lm.result3$coefficients
lm.result6$coefficients
lm.result6 <- lm(formula = z1 ~ z2, data = data1)
lm.result3$coefficients
lm.result6$coefficients
data2 <- data.frame(z1 = residuals(lm.result1), z2 = residuals(lm.result5))
data1 <- data.frame(z1 = residuals(lm.result2), z2 = residuals((lm.result4)))
data1 <- data.frame(z1 = residuals(lm.result2), z2 = residuals(lm.result4))
data2 <- data.frame(z1 = residuals(lm.result1), z2 = residuals(lm.result5))
lm.result7 <- lm(formula = z1 ~ z2, data = data2)
lm.result7$coefficients
lm.result$coefficients
Example8.6 <- read.csv("Example8.6.csv", header = T)
lm(formula = y ~ x1, data = Example8.6)
Example8.6 <- read.csv("Example8.6.csv", header = T)
Example8.6
Example8.6$z <- factor(Example8.6$x1)
Example8.6
lm(formula = y ~ z, data = Example8.6)
lm(formula = y ~ x1 + x2 + x3, data = Example8.6)
Example8.6
lm(formula = y ~ z, data = Example8.6)
full.md <- lm(formula = y ~ z, data = Example8.6)
reduced.md <- lm(formula = y ~ x1, data = Example8.6)
anova(reduced.md, full.md)
data$z1 <- factor(data$x1)
full.lm1 <- lm(formula = y ~ z1, data = data)
full.lm1
data <- data.frame(x1 = x1, x2 = x2, y = y)
data
cor(Example8.6$x1,Example8.6$x2)
cor(Example8.6$x1,Example8.6$x3)
cor(Example8.6$x2,Example8.6$x3)
# 1번
y <- c(40,50,62,68,86,102,116,124)
x1 <- c(2,2,2,4,4,2,6,5)
x2 <- c('고졸','고졸','고졸','고졸','대졸','고졸','대졸','고졸')
data.set <- data.frame(y = y, x1 = x1, x2 = x2)
data.set$x2 <- factor(data.set$x2, levels = c('대졸','고졸'))
lm.result1 <- lm(formula = y ~ x1 + x2 + x1:x2 , data = data.set)
summary(lm.result1) # 교호작용의 유의확률이 가장 큼
lm.result2 <- lm(formula = y ~ x1 + x2, data = data.set)
summary(lm.result2) # x2의 유의확률이 가장 큼
lm.result3 <- lm(formula = y ~ x1, data = data.set)
summary(lm.result3) # 절편항이 유의하지 않음
lm.result4 <- lm(formula = y ~ 0 + x1, data = data.set)
summary(lm.result4) # 최종모형으로 선택
lm.result2 <- lm(formula = y ~ x1 + x2, data = data.set)
summary(lm.result2) # x2의 유의확률이 가장 큼
lm.result3 <- lm(formula = y ~ x1, data = data.set)
summary(lm.result3) # 절편항이 유의하지 않음
lm.result4 <- lm(formula = y ~ 0 + x1, data = data.set)
summary(lm.result4) # 최종모형으로 선택
# 2번
x <- c(20,20,20,40,40,40,60,60,60)
y <- c(86,80,77,78,84,75,33,38,43)
data.set2 <- data.frame(x = x, y = y)
data.set2$z1 <- ifelse(data.set2$x == 40, 1, 0)
data.set2$z2 <- ifelse(data.set2$x == 60, 1, 0)
lm(formula = y ~ z1 + z2, data = data.set2)
# 3번
x <- c(285,264,276,302,248,296,274,284,253,269)
y <- c(1,0,0,1,1,0,1,0,1,1)
data.set3 <- data.frame(x = x, y = y)
glm.result <- glm(formula = y ~ x, family = binomial, data = data.set3)
newdata <- data.frame(x = 290)
predict(glm.result, newdata = newdata, type = 'response')
# 4번
x <- c(1,2,3,4,5,6)
n <- c(250,252,151,204,202,195)
y <- c(15,20,18,25,32,41)
data.set4 <- data.frame(x = x, n = n, y = y)
data.set4$z <- data.set4$n - data.set4$y
glm.result2 <- glm(formula = cbind(y,z) ~ x, family = binomial, data = data.set4)
summary(glm.result2)
# 3번
x <- c(285,264,276,302,248,296,274,284,253,269)
y <- c(1,0,0,1,1,0,1,0,1,1)
data.set3 <- data.frame(x = x, y = y)
glm.result <- glm(formula = y ~ x, family = binomial, data = data.set3)
glm.result
data.set3$y <- factor(data.set$y , levels = c("1" , "0"))
data.set3$y <- factor(data.set3$y , levels = c("1" , "0"))
# 3번
x <- c(285,264,276,302,248,296,274,284,253,269)
y <- c(1,0,0,1,1,0,1,0,1,1)
data.set3 <- data.frame(x = x, y = y)
data.set3$y <- factor(data.set3$y , levels = c("1" , "0"))
glm.result <- glm(formula = y ~ x, family = binomial, data = data.set3)
newdata <- data.frame(x = 290)
predict(glm.result, newdata = newdata, type = 'response')
glm.result
# 반응변수가 지시변수인 경우: 로지스틱 회귀
data.set <- read.csv( "Data/Example10.4.csv" )
getwd()
# 반응변수가 지시변수인 경우: 로지스틱 회귀
data.set <- read.csv( "J:/수업/2022학년도/회귀분석실습/Example10.4.csv" )
data.set$y <- factor( data.set$y , levels = c( "1" , "0" ) )
data.set
# 3번
x <- c(285,264,276,302,248,296,274,284,253,269)
y <- c(1,0,0,1,1,0,1,0,1,1)
data.set3 <- data.frame(x = x, y = y)
glm.result <- glm(formula = y ~ x, family = binomial, data = data.set3)
newdata <- data.frame(x = 290)
predict(glm.result, newdata = newdata, type = 'response')
data.set <- read.csv( "J:/수업/2022학년도/회귀분석실습/Example10.5.csv" )
data.set$z <- data.set$n - data.set$y
glm(formula = y/n ~ x, family = binomial, data = data.set)
glm.result <- glm( formula = cbind( y , z ) ~ x , family = quasi , data = data.set  )
glm(formula = y/n ~ x, family = quasi, data = data.set)
glm.result <- glm( formula = cbind( y , z ) ~ x , family = binomial , data = data.set  )
glm.result
data.set <- read.csv( "J:/수업/2022학년도/회귀분석실습/Example10.5.csv" )
data.set$z <- data.set$n - data.set$y
glm.result <- glm( formula = cbind( y , z ) ~ x , family = binomial , data = data.set  )
new.data <- data.frame( x = 35 )
predict( glm.result , newdata = new.data , type = "response" )
newdata <- data.frame(x = c(1,2,3,4,5,6))
# 1번
y <- c(40,50,62,68,86,102,116,124)
x1 <- c(2,2,2,4,4,2,6,5)
x2 <- c('고졸','고졸','고졸','고졸','대졸','고졸','대졸','고졸')
data.set <- data.frame(y = y, x1 = x1, x2 = x2)
data.set$x2 <- factor(data.set$x2, levels = c('대졸','고졸'))
lm.result1 <- lm(formula = y ~ x1 + x2 + x1:x2 , data = data.set)
summary(lm.result1) # 교호작용의 유의확률이 가장 큼
lm.result2 <- lm(formula = y ~ x1 + x2, data = data.set)
summary(lm.result2) # x2의 유의확률이 가장 큼
lm.result3 <- lm(formula = y ~ x1, data = data.set)
summary(lm.result3) # 절편항이 유의하지 않음
lm.result4 <- lm(formula = y ~ 0 + x1, data = data.set)
summary(lm.result4) # 최종모형으로 선택
# 2번
x <- c(20,20,20,40,40,40,60,60,60)
y <- c(86,80,77,78,84,75,33,38,43)
data.set2 <- data.frame(x = x, y = y)
data.set2$z1 <- ifelse(data.set2$x == 40, 1, 0)
data.set2$z2 <- ifelse(data.set2$x == 60, 1, 0)
lm(formula = y ~ z1 + z2, data = data.set2)
# 3번
x <- c(285,264,276,302,248,296,274,284,253,269)
y <- c(1,0,0,1,1,0,1,0,1,1)
data.set3 <- data.frame(x = x, y = y)
glm.result <- glm(formula = y ~ x, family = binomial, data = data.set3)
newdata <- data.frame(x = 290)
predict(glm.result, newdata = newdata, type = 'response')
# 4번
x <- c(1,2,3,4,5,6)
n <- c(250,252,151,204,202,195)
y <- c(15,20,18,25,32,41)
data.set4 <- data.frame(x = x, n = n, y = y)
data.set4$z <- data.set4$n - data.set4$y
glm.result2 <- glm(formula = cbind(y,z) ~ x, family = binomial, data = data.set4)
summary(glm.result2)
newdata <- data.frame(x = c(1,2,3,4,5,6))
predict(glm.result2, newdata = newdata, type = 'response')
x1 <- c(10,8,12,7,12,8,12,5,8,5,11,12,6,10,10)
x2 <- c(8,6,9,16,17,15,8,10,4,16,7,12,6,4,4)
x3 <- c(5.5,2.5,8,3,2.9,3.0,8,9,4,6.5,5.5,5,6,5,3.5)
y <- c(79,200,163,200,178,146,31,292,160,339,160,86,237,107,155)
data.set <- data.frame(x1 = x1, x2 = x2, x3 = x3, y = y)
data.set
library(leaps)
result <- regsubsets(y~x1+x2+x3,data = data.set)
summary.result <- summary(result) # all possible regression
summary.result$cp
summary.result$adjr2
summary.result$adjr2
summary(result)
summary.result
best.model <- lm(y~x1+x2,data = data.set)
summary(best.model)
result <- regsubsets(y~.,data = data.set)
summary.result <- summary(result) # all possible regression
summary.result$cp # 변수 2개를 사용했을 때가 적절
summary.result$adjr2 # 변수 2개를 사용했을 때가 적절
summary.result # x1, x2를 사용
best.model <- lm(y~x1+x2,data = data.set)
summary(best.model) # 최종 모형
result <- regsubsets(y~.,data = data.set)
summary.result <- summary(result) # all possible regression
summary.result$cp # 변수 2개를 사용했을 때가 적절
summary.result$adjr2 # 변수 2개를 사용했을 때가 적절
summary.result # x1, x2를 사용
lm.result <- lm(y~.,data = data.set)
fw <- step(lm.result, direction = 'forward') # forward selection
summary(fw)
lm.result <- lm(y~.,data = data.set)
fw <- step(lm.result, direction = 'forward') # forward selection
summary(fw)
bw <- step(lm.result, direction = 'backward') # backward elimination
bw <- step(lm.result, direction = 'backward') # backward elimination
summary(bw)
sw <- step(lm.result, direction = 'both') # stepwise regression
summary(sw)
summary(bw)
summary(sw)
lm.result <- lm(y~.,data = data.set)
fw <- step(lm.result, direction = 'forward') # forward selection
summary(fw)
setwd('H:/수업/2022학년도/탐색적자료분석실습')
Telemetric <- read.table('Telemetric.txt', header = T)
str(Telemetric)
plot(temperature~day, data = Telemetric)
plot(Telemetric$temperature, type = 'l'. lty = 2)
plot(Telemetric$temperature, type = 'l', lty = 2)
plot(temperature~day, data = Telemetric)
plot(temperature~day, data = Telemetric, type = 'l')
plot(Telemetric$temperature, type = 'l', lty = 2)
plot(temperature~day, data = Telemetric, type = 'l')
par(new=T)
a <- smooth(Telemetric$temperature)
a <- smooth(Telemetric$temperature twiceit = T)
a <- smooth(Telemetric$temperature twiceit = T)
a <- smooth(Telemetric$temperature, twiceit = T)
plot(a, type = 'l', col = 'blue')
plot(a, type = 'l', col = 'blue')
b <- smooth(Telemetric$temperature)
plot(b, type = 'l')
plot(a, type = 'l', col = 'blue')
plot(b, type = 'l')
Export <- read.table("Export_1988.txt", header = T)
Export
Series <- ts(Export$Series/1000, start = c(1988,1), frequency = 12)
Series
str(Export)
plot(Series)
Log.Series <- log(Series)
decomp.out <- decompose(Log.Series)
decomp.out$seasonal
decomp.out$seasonal[1:12]
Season <- decomp.out$seasonal[1:12]
plot(decomp.out$trend)
plot(decomp.out$trend + decomp.out$seasonal)
decomp.out
Adjusted <- exp(Log.Series - decomp.out$seasonal)
Adjusted1 <- exp(decomp.out$x - decomp.out$seasonal)
Adjusted
Adjusted1
plot(Adjusted1)
Adj.Series <- ts(Adjusted, start=c(1988,1), frequency=12)
plot(Adj.Series, ylim=c(5000,25000))
plot(Adjusted1)
library(MASS)
geyser
attach(geyser)
acf(waiting)
acf(duration)
plot(duration ~ waiting)
acf(waiting)
acf(waiting)$acf[1:5]
ccf.geyser <- ccf(waiting,duration)
cbind(ccf.geyser$lag, ccf.geyser$acf)
plot(waiting[2:299]~duration[1:298]) # 해석
plot(duration[2:299]~duration[1:298]) # 해석
library(foreign)
ee <- read.spss("EEstock2000.sav")
x <- ee$change
plot(x)
plot(x,type = 'l')
acf(x)
m <- mean(x) ; sd <- sd(x)
hist(x, freq = F, nclass = 20)
curve(dnorm(x,m,sd), add = T)
